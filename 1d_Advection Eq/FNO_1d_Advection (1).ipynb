{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frIlYnTWxMWL"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "from timeit import default_timer\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "class SpectralConv1d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, modes1):\n",
        "        super().__init__()\n",
        "\n",
        "        \"\"\"\n",
        "        1D Fourier layer. It does FFT, linear transform, and Inverse FFT.\n",
        "        \"\"\"\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.modes1 = (\n",
        "            # Number of Fourier modes to multiply, at most floor(N/2) + 1\n",
        "            modes1\n",
        "        )\n",
        "\n",
        "        self.scale = 1 / (in_channels * out_channels)\n",
        "        self.weights1 = nn.Parameter(\n",
        "            self.scale\n",
        "            * torch.rand(in_channels, out_channels, self.modes1, dtype=torch.cfloat)\n",
        "        )\n",
        "\n",
        "    # Complex multiplication\n",
        "    def compl_mul1d(self, input, weights):\n",
        "        # (batch, in_channel, x ), (in_channel, out_channel, x) -> (batch, out_channel, x)\n",
        "        return torch.einsum(\"bix,iox->box\", input, weights)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batchsize = x.shape[0]\n",
        "        # Compute Fourier coefficients up to factor of e^(- something constant)\n",
        "        x_ft = torch.fft.rfft(x)\n",
        "\n",
        "        # Multiply relevant Fourier modes\n",
        "        out_ft = torch.zeros(\n",
        "            batchsize,\n",
        "            self.out_channels,\n",
        "            x.size(-1) // 2 + 1,\n",
        "            device=x.device,\n",
        "            dtype=torch.cfloat,\n",
        "        )\n",
        "        out_ft[:, :, : self.modes1] = self.compl_mul1d(\n",
        "            x_ft[:, :, : self.modes1], self.weights1\n",
        "        )\n",
        "\n",
        "        # Return to physical space\n",
        "        return torch.fft.irfft(out_ft, n=x.size(-1))\n",
        "\n",
        "\n",
        "class FNO1d(nn.Module):\n",
        "    def __init__(self, num_channels, modes=16, width=64, initial_step=10):\n",
        "        super().__init__()\n",
        "\n",
        "        \"\"\"\n",
        "        The overall network. It contains 4 layers of the Fourier layer.\n",
        "        1. Lift the input to the desire channel dimension by self.fc0 .\n",
        "        2. 4 layers of the integral operators u' = (W + K)(u).\n",
        "            W defined by self.w; K defined by self.conv .\n",
        "        3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n",
        "\n",
        "        input: the solution of the initial condition and location (a(x), x)\n",
        "        input shape: (batchsize, x=s, c=2)\n",
        "        output: the solution of a later timestep\n",
        "        output shape: (batchsize, x=s, c=1)\n",
        "        \"\"\"\n",
        "\n",
        "        self.modes1 = modes\n",
        "        self.width = width\n",
        "        self.padding = 2  # pad the domain if input is non-periodic\n",
        "        self.fc0 = nn.Linear(\n",
        "            initial_step * num_channels + 1, self.width\n",
        "        )  # input channel is 2: (a(x), x)\n",
        "\n",
        "        self.conv0 = SpectralConv1d(self.width, self.width, self.modes1)\n",
        "        self.conv1 = SpectralConv1d(self.width, self.width, self.modes1)\n",
        "        self.conv2 = SpectralConv1d(self.width, self.width, self.modes1)\n",
        "        self.conv3 = SpectralConv1d(self.width, self.width, self.modes1)\n",
        "        self.w0 = nn.Conv1d(self.width, self.width, 1)\n",
        "        self.w1 = nn.Conv1d(self.width, self.width, 1)\n",
        "        self.w2 = nn.Conv1d(self.width, self.width, 1)\n",
        "        self.w3 = nn.Conv1d(self.width, self.width, 1)\n",
        "\n",
        "        self.fc1 = nn.Linear(self.width, 128)\n",
        "        self.fc2 = nn.Linear(128, num_channels)\n",
        "\n",
        "    def forward(self, x, grid):\n",
        "        # x dim = [b, x1, t*v]\n",
        "        x = torch.cat((x, grid), dim=-1)\n",
        "        x = self.fc0(x)\n",
        "        x = x.permute(0, 2, 1)\n",
        "\n",
        "        # pad the domain if input is non-periodic\n",
        "        x = F.pad(x, [0, self.padding])\n",
        "\n",
        "        x1 = self.conv0(x)\n",
        "        x2 = self.w0(x)\n",
        "        x = x1 + x2\n",
        "        x = F.gelu(x)\n",
        "\n",
        "        x1 = self.conv1(x)\n",
        "        x2 = self.w1(x)\n",
        "        x = x1 + x2\n",
        "        x = F.gelu(x)\n",
        "\n",
        "        x1 = self.conv2(x)\n",
        "        x2 = self.w2(x)\n",
        "        x = x1 + x2\n",
        "        x = F.gelu(x)\n",
        "\n",
        "        x1 = self.conv3(x)\n",
        "        x2 = self.w3(x)\n",
        "        x = x1 + x2\n",
        "\n",
        "        x = x[..., : -self.padding]\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.gelu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x.unsqueeze(-2)"
      ],
      "metadata": {
        "id": "t9G7ywF8xiOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import math as mt\n",
        "from pathlib import Path\n",
        "\n",
        "import h5py\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class FNODatasetSingle(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        filename,\n",
        "        initial_step=10,\n",
        "        saved_folder=\"../data/\",\n",
        "        reduced_resolution=1,\n",
        "        reduced_resolution_t=1,\n",
        "        reduced_batch=1,\n",
        "        if_test=False,\n",
        "        test_ratio=0.1,\n",
        "        num_samples_max=-1,\n",
        "    ):\n",
        "        \"\"\"\n",
        "\n",
        "        :param filename: filename that contains the dataset\n",
        "        :type filename: STR\n",
        "        :param filenum: array containing indices of filename included in the dataset\n",
        "        :type filenum: ARRAY\n",
        "        :param initial_step: time steps taken as initial condition, defaults to 10\n",
        "        :type initial_step: INT, optional\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        # Define path to files\n",
        "        root_path = Path(Path(saved_folder).resolve()) / filename\n",
        "        if filename[-2:] != \"h5\":\n",
        "            # print(\".HDF5 file extension is assumed hereafter\")\n",
        "\n",
        "            with h5py.File(root_path, \"r\") as f:\n",
        "                keys = list(f.keys())\n",
        "                keys.sort()\n",
        "                if \"tensor\" not in keys:\n",
        "                    _data = np.array(\n",
        "                        f[\"density\"], dtype=np.float32\n",
        "                    )  # batch, time, x,...\n",
        "                    idx_cfd = _data.shape\n",
        "                    if len(idx_cfd) == 3:  # 1D\n",
        "                        self.data = np.zeros(\n",
        "                            [\n",
        "                                idx_cfd[0] // reduced_batch,\n",
        "                                idx_cfd[2] // reduced_resolution,\n",
        "                                mt.ceil(idx_cfd[1] / reduced_resolution_t),\n",
        "                                3,\n",
        "                            ],\n",
        "                            dtype=np.float32,\n",
        "                        )\n",
        "                        # density\n",
        "                        _data = _data[\n",
        "                            ::reduced_batch,\n",
        "                            ::reduced_resolution_t,\n",
        "                            ::reduced_resolution,\n",
        "                        ]\n",
        "                        ## convert to [x1, ..., xd, t, v]\n",
        "                        _data = np.transpose(_data[:, :, :], (0, 2, 1))\n",
        "                        self.data[..., 0] = _data  # batch, x, t, ch\n",
        "                        # pressure\n",
        "                        _data = np.array(\n",
        "                            f[\"pressure\"], dtype=np.float32\n",
        "                        )  # batch, time, x,...\n",
        "                        _data = _data[\n",
        "                            ::reduced_batch,\n",
        "                            ::reduced_resolution_t,\n",
        "                            ::reduced_resolution,\n",
        "                        ]\n",
        "                        ## convert to [x1, ..., xd, t, v]\n",
        "                        _data = np.transpose(_data[:, :, :], (0, 2, 1))\n",
        "                        self.data[..., 1] = _data  # batch, x, t, ch\n",
        "                        # Vx\n",
        "                        _data = np.array(\n",
        "                            f[\"Vx\"], dtype=np.float32\n",
        "                        )  # batch, time, x,...\n",
        "                        _data = _data[\n",
        "                            ::reduced_batch,\n",
        "                            ::reduced_resolution_t,\n",
        "                            ::reduced_resolution,\n",
        "                        ]\n",
        "                        ## convert to [x1, ..., xd, t, v]\n",
        "                        _data = np.transpose(_data[:, :, :], (0, 2, 1))\n",
        "                        self.data[..., 2] = _data  # batch, x, t, ch\n",
        "\n",
        "                        self.grid = np.array(f[\"x-coordinate\"], dtype=np.float32)\n",
        "                        self.grid = torch.tensor(\n",
        "                            self.grid[::reduced_resolution], dtype=torch.float\n",
        "                        ).unsqueeze(-1)\n",
        "                        # print(self.data.shape)\n",
        "                    if len(idx_cfd) == 4:  # 2D\n",
        "                        self.data = np.zeros(\n",
        "                            [\n",
        "                                idx_cfd[0] // reduced_batch,\n",
        "                                idx_cfd[2] // reduced_resolution,\n",
        "                                idx_cfd[3] // reduced_resolution,\n",
        "                                mt.ceil(idx_cfd[1] / reduced_resolution_t),\n",
        "                                4,\n",
        "                            ],\n",
        "                            dtype=np.float32,\n",
        "                        )\n",
        "                        # density\n",
        "                        _data = _data[\n",
        "                            ::reduced_batch,\n",
        "                            ::reduced_resolution_t,\n",
        "                            ::reduced_resolution,\n",
        "                            ::reduced_resolution,\n",
        "                        ]\n",
        "                        ## convert to [x1, ..., xd, t, v]\n",
        "                        _data = np.transpose(_data, (0, 2, 3, 1))\n",
        "                        self.data[..., 0] = _data  # batch, x, t, ch\n",
        "                        # pressure\n",
        "                        _data = np.array(\n",
        "                            f[\"pressure\"], dtype=np.float32\n",
        "                        )  # batch, time, x,...\n",
        "                        _data = _data[\n",
        "                            ::reduced_batch,\n",
        "                            ::reduced_resolution_t,\n",
        "                            ::reduced_resolution,\n",
        "                            ::reduced_resolution,\n",
        "                        ]\n",
        "                        ## convert to [x1, ..., xd, t, v]\n",
        "                        _data = np.transpose(_data, (0, 2, 3, 1))\n",
        "                        self.data[..., 1] = _data  # batch, x, t, ch\n",
        "                        # Vx\n",
        "                        _data = np.array(\n",
        "                            f[\"Vx\"], dtype=np.float32\n",
        "                        )  # batch, time, x,...\n",
        "                        _data = _data[\n",
        "                            ::reduced_batch,\n",
        "                            ::reduced_resolution_t,\n",
        "                            ::reduced_resolution,\n",
        "                            ::reduced_resolution,\n",
        "                        ]\n",
        "                        ## convert to [x1, ..., xd, t, v]\n",
        "                        _data = np.transpose(_data, (0, 2, 3, 1))\n",
        "                        self.data[..., 2] = _data  # batch, x, t, ch\n",
        "                        # Vy\n",
        "                        _data = np.array(\n",
        "                            f[\"Vy\"], dtype=np.float32\n",
        "                        )  # batch, time, x,...\n",
        "                        _data = _data[\n",
        "                            ::reduced_batch,\n",
        "                            ::reduced_resolution_t,\n",
        "                            ::reduced_resolution,\n",
        "                            ::reduced_resolution,\n",
        "                        ]\n",
        "                        ## convert to [x1, ..., xd, t, v]\n",
        "                        _data = np.transpose(_data, (0, 2, 3, 1))\n",
        "                        self.data[..., 3] = _data  # batch, x, t, ch\n",
        "\n",
        "                        x = np.array(f[\"x-coordinate\"], dtype=np.float32)\n",
        "                        y = np.array(f[\"y-coordinate\"], dtype=np.float32)\n",
        "                        x = torch.tensor(x, dtype=torch.float)\n",
        "                        y = torch.tensor(y, dtype=torch.float)\n",
        "                        X, Y = torch.meshgrid(x, y, indexing=\"ij\")\n",
        "                        self.grid = torch.stack((X, Y), axis=-1)[\n",
        "                            ::reduced_resolution, ::reduced_resolution\n",
        "                        ]\n",
        "\n",
        "                    if len(idx_cfd) == 5:  # 3D\n",
        "                        self.data = np.zeros(\n",
        "                            [\n",
        "                                idx_cfd[0] // reduced_batch,\n",
        "                                idx_cfd[2] // reduced_resolution,\n",
        "                                idx_cfd[3] // reduced_resolution,\n",
        "                                idx_cfd[4] // reduced_resolution,\n",
        "                                mt.ceil(idx_cfd[1] / reduced_resolution_t),\n",
        "                                5,\n",
        "                            ],\n",
        "                            dtype=np.float32,\n",
        "                        )\n",
        "                        # density\n",
        "                        _data = _data[\n",
        "                            ::reduced_batch,\n",
        "                            ::reduced_resolution_t,\n",
        "                            ::reduced_resolution,\n",
        "                            ::reduced_resolution,\n",
        "                            ::reduced_resolution,\n",
        "                        ]\n",
        "                        ## convert to [x1, ..., xd, t, v]\n",
        "                        _data = np.transpose(_data, (0, 2, 3, 4, 1))\n",
        "                        self.data[..., 0] = _data  # batch, x, t, ch\n",
        "                        # pressure\n",
        "                        _data = np.array(\n",
        "                            f[\"pressure\"], dtype=np.float32\n",
        "                        )  # batch, time, x,...\n",
        "                        _data = _data[\n",
        "                            ::reduced_batch,\n",
        "                            ::reduced_resolution_t,\n",
        "                            ::reduced_resolution,\n",
        "                            ::reduced_resolution,\n",
        "                            ::reduced_resolution,\n",
        "                        ]\n",
        "                        ## convert to [x1, ..., xd, t, v]\n",
        "                        _data = np.transpose(_data, (0, 2, 3, 4, 1))\n",
        "                        self.data[..., 1] = _data  # batch, x, t, ch\n",
        "                        # Vx\n",
        "                        _data = np.array(\n",
        "                            f[\"Vx\"], dtype=np.float32\n",
        "                        )  # batch, time, x,...\n",
        "                        _data = _data[\n",
        "                            ::reduced_batch,\n",
        "                            ::reduced_resolution_t,\n",
        "                            ::reduced_resolution,\n",
        "                            ::reduced_resolution,\n",
        "                            ::reduced_resolution,\n",
        "                        ]\n",
        "                        ## convert to [x1, ..., xd, t, v]\n",
        "                        _data = np.transpose(_data, (0, 2, 3, 4, 1))\n",
        "                        self.data[..., 2] = _data  # batch, x, t, ch\n",
        "                        # Vy\n",
        "                        _data = np.array(\n",
        "                            f[\"Vy\"], dtype=np.float32\n",
        "                        )  # batch, time, x,...\n",
        "                        _data = _data[\n",
        "                            ::reduced_batch,\n",
        "                            ::reduced_resolution_t,\n",
        "                            ::reduced_resolution,\n",
        "                            ::reduced_resolution,\n",
        "                            ::reduced_resolution,\n",
        "                        ]\n",
        "                        ## convert to [x1, ..., xd, t, v]\n",
        "                        _data = np.transpose(_data, (0, 2, 3, 4, 1))\n",
        "                        self.data[..., 3] = _data  # batch, x, t, ch\n",
        "                        # Vz\n",
        "                        _data = np.array(\n",
        "                            f[\"Vz\"], dtype=np.float32\n",
        "                        )  # batch, time, x,...\n",
        "                        _data = _data[\n",
        "                            ::reduced_batch,\n",
        "                            ::reduced_resolution_t,\n",
        "                            ::reduced_resolution,\n",
        "                            ::reduced_resolution,\n",
        "                            ::reduced_resolution,\n",
        "                        ]\n",
        "                        ## convert to [x1, ..., xd, t, v]\n",
        "                        _data = np.transpose(_data, (0, 2, 3, 4, 1))\n",
        "                        self.data[..., 4] = _data  # batch, x, t, ch\n",
        "\n",
        "                        x = np.array(f[\"x-coordinate\"], dtype=np.float32)\n",
        "                        y = np.array(f[\"y-coordinate\"], dtype=np.float32)\n",
        "                        z = np.array(f[\"z-coordinate\"], dtype=np.float32)\n",
        "                        x = torch.tensor(x, dtype=torch.float)\n",
        "                        y = torch.tensor(y, dtype=torch.float)\n",
        "                        z = torch.tensor(z, dtype=torch.float)\n",
        "                        X, Y, Z = torch.meshgrid(x, y, z, indexing=\"ij\")\n",
        "                        self.grid = torch.stack((X, Y, Z), axis=-1)[\n",
        "                            ::reduced_resolution,\n",
        "                            ::reduced_resolution,\n",
        "                            ::reduced_resolution,\n",
        "                        ]\n",
        "\n",
        "                else:  # scalar equations\n",
        "                    ## data dim = [t, x1, ..., xd, v]\n",
        "                    _data = np.array(\n",
        "                        f[\"tensor\"], dtype=np.float32\n",
        "                    )  # batch, time, x,...\n",
        "                    if len(_data.shape) == 3:  # 1D\n",
        "                        _data = _data[\n",
        "                            ::reduced_batch,\n",
        "                            ::reduced_resolution_t,\n",
        "                            ::reduced_resolution,\n",
        "                        ]\n",
        "                        ## convert to [x1, ..., xd, t, v]\n",
        "                        _data = np.transpose(_data[:, :, :], (0, 2, 1))\n",
        "                        self.data = _data[:, :, :, None]  # batch, x, t, ch\n",
        "\n",
        "                        self.grid = np.array(f[\"x-coordinate\"], dtype=np.float32)\n",
        "                        self.grid = torch.tensor(\n",
        "                            self.grid[::reduced_resolution], dtype=torch.float\n",
        "                        ).unsqueeze(-1)\n",
        "                    if len(_data.shape) == 4:  # 2D Darcy flow\n",
        "                        # u: label\n",
        "                        _data = _data[\n",
        "                            ::reduced_batch,\n",
        "                            :,\n",
        "                            ::reduced_resolution,\n",
        "                            ::reduced_resolution,\n",
        "                        ]\n",
        "                        ## convert to [x1, ..., xd, t, v]\n",
        "                        _data = np.transpose(_data[:, :, :, :], (0, 2, 3, 1))\n",
        "                        # if _data.shape[-1]==1:  # if nt==1\n",
        "                        #    _data = np.tile(_data, (1, 1, 1, 2))\n",
        "                        self.data = _data\n",
        "                        # nu: input\n",
        "                        _data = np.array(\n",
        "                            f[\"nu\"], dtype=np.float32\n",
        "                        )  # batch, time, x,...\n",
        "                        _data = _data[\n",
        "                            ::reduced_batch,\n",
        "                            None,\n",
        "                            ::reduced_resolution,\n",
        "                            ::reduced_resolution,\n",
        "                        ]\n",
        "                        ## convert to [x1, ..., xd, t, v]\n",
        "                        _data = np.transpose(_data[:, :, :, :], (0, 2, 3, 1))\n",
        "                        self.data = np.concatenate([_data, self.data], axis=-1)\n",
        "                        self.data = self.data[:, :, :, :, None]  # batch, x, y, t, ch\n",
        "\n",
        "                        x = np.array(f[\"x-coordinate\"], dtype=np.float32)\n",
        "                        y = np.array(f[\"y-coordinate\"], dtype=np.float32)\n",
        "                        x = torch.tensor(x, dtype=torch.float)\n",
        "                        y = torch.tensor(y, dtype=torch.float)\n",
        "                        X, Y = torch.meshgrid(x, y, indexing=\"ij\")\n",
        "                        self.grid = torch.stack((X, Y), axis=-1)[\n",
        "                            ::reduced_resolution, ::reduced_resolution\n",
        "                        ]\n",
        "\n",
        "        elif filename[-2:] == \"h5\":  # SWE-2D (RDB)\n",
        "            # print(\".H5 file extension is assumed hereafter\")\n",
        "\n",
        "            with h5py.File(root_path, \"r\") as f:\n",
        "                keys = list(f.keys())\n",
        "                keys.sort()\n",
        "\n",
        "                data_arrays = [\n",
        "                    np.array(f[key][\"data\"], dtype=np.float32) for key in keys\n",
        "                ]\n",
        "                _data = torch.from_numpy(\n",
        "                    np.stack(data_arrays, axis=0)\n",
        "                )  # [batch, nt, nx, ny, nc]\n",
        "                _data = _data[\n",
        "                    ::reduced_batch,\n",
        "                    ::reduced_resolution_t,\n",
        "                    ::reduced_resolution,\n",
        "                    ::reduced_resolution,\n",
        "                    ...,\n",
        "                ]\n",
        "                _data = torch.permute(_data, (0, 2, 3, 1, 4))  # [batch, nx, ny, nt, nc]\n",
        "                gridx, gridy = (\n",
        "                    np.array(f[\"0023\"][\"grid\"][\"x\"], dtype=np.float32),\n",
        "                    np.array(f[\"0023\"][\"grid\"][\"y\"], dtype=np.float32),\n",
        "                )\n",
        "                mgridX, mgridY = np.meshgrid(gridx, gridy, indexing=\"ij\")\n",
        "                _grid = torch.stack(\n",
        "                    (torch.from_numpy(mgridX), torch.from_numpy(mgridY)), axis=-1\n",
        "                )\n",
        "                _grid = _grid[::reduced_resolution, ::reduced_resolution, ...]\n",
        "                _tsteps_t = torch.from_numpy(\n",
        "                    np.array(f[\"0023\"][\"grid\"][\"t\"], dtype=np.float32)\n",
        "                )\n",
        "\n",
        "                tsteps_t = _tsteps_t[::reduced_resolution_t]\n",
        "                self.data = _data\n",
        "                self.grid = _grid\n",
        "                self.tsteps_t = tsteps_t\n",
        "\n",
        "        if num_samples_max > 0:\n",
        "            num_samples_max = min(num_samples_max, self.data.shape[0])\n",
        "        else:\n",
        "            num_samples_max = self.data.shape[0]\n",
        "\n",
        "        test_idx = int(num_samples_max * test_ratio)\n",
        "        if if_test:\n",
        "            self.data = self.data[:test_idx]\n",
        "        else:\n",
        "            self.data = self.data[test_idx:num_samples_max]\n",
        "\n",
        "        # Time steps used as initial conditions\n",
        "        self.initial_step = initial_step\n",
        "\n",
        "        self.data = self.data if torch.is_tensor(self.data) else torch.tensor(self.data)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx, ..., : self.initial_step, :], self.data[idx], self.grid"
      ],
      "metadata": {
        "id": "2-CSkT8XxiLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import logging\n",
        "import math as mt\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "from torch import nn\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "def metric_func(\n",
        "    pred, target, if_mean=True, Lx=1.0, Ly=1.0, Lz=1.0, iLow=4, iHigh=12, initial_step=1\n",
        "):\n",
        "    \"\"\"\n",
        "    code for calculate metrics discussed in the Brain-storming session\n",
        "    RMSE, normalized RMSE, max error, RMSE at the boundaries, conserved variables, RMSE in Fourier space, temporal sensitivity\n",
        "    \"\"\"\n",
        "    pred, target = pred.to(device), target.to(device)\n",
        "    # (batch, nx^i..., timesteps, nc)\n",
        "    # slice out `initial context` timesteps\n",
        "    pred = pred[..., initial_step:, :]\n",
        "    target = target[..., initial_step:, :]\n",
        "    idxs = target.size()\n",
        "    if len(idxs) == 4:  # 1D\n",
        "        pred = pred.permute(0, 3, 1, 2)\n",
        "        target = target.permute(0, 3, 1, 2)\n",
        "    if len(idxs) == 5:  # 2D\n",
        "        pred = pred.permute(0, 4, 1, 2, 3)\n",
        "        target = target.permute(0, 4, 1, 2, 3)\n",
        "    elif len(idxs) == 6:  # 3D\n",
        "        pred = pred.permute(0, 5, 1, 2, 3, 4)\n",
        "        target = target.permute(0, 5, 1, 2, 3, 4)\n",
        "    idxs = target.size()\n",
        "    nb, nc, nt = idxs[0], idxs[1], idxs[-1]\n",
        "\n",
        "    # RMSE\n",
        "    err_mean = torch.sqrt(\n",
        "        torch.mean(\n",
        "            (pred.view([nb, nc, -1, nt]) - target.view([nb, nc, -1, nt])) ** 2, dim=2\n",
        "        )\n",
        "    )\n",
        "    err_RMSE = torch.mean(err_mean, axis=0)\n",
        "    nrm = torch.sqrt(torch.mean(target.view([nb, nc, -1, nt]) ** 2, dim=2))\n",
        "    err_nRMSE = torch.mean(err_mean / nrm, dim=0)\n",
        "\n",
        "    err_CSV = torch.sqrt(\n",
        "        torch.mean(\n",
        "            (\n",
        "                torch.sum(pred.view([nb, nc, -1, nt]), dim=2)\n",
        "                - torch.sum(target.view([nb, nc, -1, nt]), dim=2)\n",
        "            )\n",
        "            ** 2,\n",
        "            dim=0,\n",
        "        )\n",
        "    )\n",
        "    if len(idxs) == 4:\n",
        "        nx = idxs[2]\n",
        "        err_CSV /= nx\n",
        "    elif len(idxs) == 5:\n",
        "        nx, ny = idxs[2:4]\n",
        "        err_CSV /= nx * ny\n",
        "    elif len(idxs) == 6:\n",
        "        nx, ny, nz = idxs[2:5]\n",
        "        err_CSV /= nx * ny * nz\n",
        "    # worst case in all the data\n",
        "    err_Max = torch.max(\n",
        "        torch.max(\n",
        "            torch.abs(pred.view([nb, nc, -1, nt]) - target.view([nb, nc, -1, nt])),\n",
        "            dim=2,\n",
        "        )[0],\n",
        "        dim=0,\n",
        "    )[0]\n",
        "\n",
        "    if len(idxs) == 4:  # 1D\n",
        "        err_BD = (pred[:, :, 0, :] - target[:, :, 0, :]) ** 2\n",
        "        err_BD += (pred[:, :, -1, :] - target[:, :, -1, :]) ** 2\n",
        "        err_BD = torch.mean(torch.sqrt(err_BD / 2.0), dim=0)\n",
        "    elif len(idxs) == 5:  # 2D\n",
        "        nx, ny = idxs[2:4]\n",
        "        err_BD_x = (pred[:, :, 0, :, :] - target[:, :, 0, :, :]) ** 2\n",
        "        err_BD_x += (pred[:, :, -1, :, :] - target[:, :, -1, :, :]) ** 2\n",
        "        err_BD_y = (pred[:, :, :, 0, :] - target[:, :, :, 0, :]) ** 2\n",
        "        err_BD_y += (pred[:, :, :, -1, :] - target[:, :, :, -1, :]) ** 2\n",
        "        err_BD = (torch.sum(err_BD_x, dim=-2) + torch.sum(err_BD_y, dim=-2)) / (\n",
        "            2 * nx + 2 * ny\n",
        "        )\n",
        "        err_BD = torch.mean(torch.sqrt(err_BD), dim=0)\n",
        "    elif len(idxs) == 6:  # 3D\n",
        "        nx, ny, nz = idxs[2:5]\n",
        "        err_BD_x = (pred[:, :, 0, :, :] - target[:, :, 0, :, :]) ** 2\n",
        "        err_BD_x += (pred[:, :, -1, :, :] - target[:, :, -1, :, :]) ** 2\n",
        "        err_BD_y = (pred[:, :, :, 0, :] - target[:, :, :, 0, :]) ** 2\n",
        "        err_BD_y += (pred[:, :, :, -1, :] - target[:, :, :, -1, :]) ** 2\n",
        "        err_BD_z = (pred[:, :, :, :, 0] - target[:, :, :, :, 0]) ** 2\n",
        "        err_BD_z += (pred[:, :, :, :, -1] - target[:, :, :, :, -1]) ** 2\n",
        "        err_BD = (\n",
        "            torch.sum(err_BD_x.contiguous().view([nb, -1, nt]), dim=-2)\n",
        "            + torch.sum(err_BD_y.contiguous().view([nb, -1, nt]), dim=-2)\n",
        "            + torch.sum(err_BD_z.contiguous().view([nb, -1, nt]), dim=-2)\n",
        "        )\n",
        "        err_BD = err_BD / (2 * nx * ny + 2 * ny * nz + 2 * nz * nx)\n",
        "        err_BD = torch.sqrt(err_BD)\n",
        "\n",
        "    if len(idxs) == 4:  # 1D\n",
        "        nx = idxs[2]\n",
        "        pred_F = torch.fft.rfft(pred, dim=2)\n",
        "        target_F = torch.fft.rfft(target, dim=2)\n",
        "        _err_F = (\n",
        "            torch.sqrt(torch.mean(torch.abs(pred_F - target_F) ** 2, axis=0)) / nx * Lx\n",
        "        )\n",
        "    if len(idxs) == 5:  # 2D\n",
        "        pred_F = torch.fft.fftn(pred, dim=[2, 3])\n",
        "        target_F = torch.fft.fftn(target, dim=[2, 3])\n",
        "        nx, ny = idxs[2:4]\n",
        "        _err_F = torch.abs(pred_F - target_F) ** 2\n",
        "        err_F = torch.zeros([nb, nc, min(nx // 2, ny // 2), nt]).to(device)\n",
        "        for i in range(nx // 2):\n",
        "            for j in range(ny // 2):\n",
        "                it = mt.floor(mt.sqrt(i**2 + j**2))\n",
        "                if it > min(nx // 2, ny // 2) - 1:\n",
        "                    continue\n",
        "                err_F[:, :, it] += _err_F[:, :, i, j]\n",
        "        _err_F = torch.sqrt(torch.mean(err_F, axis=0)) / (nx * ny) * Lx * Ly\n",
        "    elif len(idxs) == 6:  # 3D\n",
        "        pred_F = torch.fft.fftn(pred, dim=[2, 3, 4])\n",
        "        target_F = torch.fft.fftn(target, dim=[2, 3, 4])\n",
        "        nx, ny, nz = idxs[2:5]\n",
        "        _err_F = torch.abs(pred_F - target_F) ** 2\n",
        "        err_F = torch.zeros([nb, nc, min(nx // 2, ny // 2, nz // 2), nt]).to(device)\n",
        "        for i in range(nx // 2):\n",
        "            for j in range(ny // 2):\n",
        "                for k in range(nz // 2):\n",
        "                    it = mt.floor(mt.sqrt(i**2 + j**2 + k**2))\n",
        "                    if it > min(nx // 2, ny // 2, nz // 2) - 1:\n",
        "                        continue\n",
        "                    err_F[:, :, it] += _err_F[:, :, i, j, k]\n",
        "        _err_F = torch.sqrt(torch.mean(err_F, axis=0)) / (nx * ny * nz) * Lx * Ly * Lz\n",
        "\n",
        "    err_F = torch.zeros([nc, 3, nt]).to(device)\n",
        "    err_F[:, 0] += torch.mean(_err_F[:, :iLow], dim=1)  # low freq\n",
        "    err_F[:, 1] += torch.mean(_err_F[:, iLow:iHigh], dim=1)  # middle freq\n",
        "    err_F[:, 2] += torch.mean(_err_F[:, iHigh:], dim=1)  # high freq\n",
        "\n",
        "    if if_mean:\n",
        "        return (\n",
        "            torch.mean(err_RMSE, dim=[0, -1]),\n",
        "            torch.mean(err_nRMSE, dim=[0, -1]),\n",
        "            torch.mean(err_CSV, dim=[0, -1]),\n",
        "            torch.mean(err_Max, dim=[0, -1]),\n",
        "            torch.mean(err_BD, dim=[0, -1]),\n",
        "            torch.mean(err_F, dim=[0, -1]),\n",
        "        )\n",
        "    return err_RMSE, err_nRMSE, err_CSV, err_Max, err_BD, err_F\n",
        "\n",
        "\n",
        "def metrics(\n",
        "    val_loader,\n",
        "    model,\n",
        "    Lx,\n",
        "    Ly,\n",
        "    Lz,\n",
        "    plot,\n",
        "    channel_plot,\n",
        "    model_name,\n",
        "    x_min,\n",
        "    x_max,\n",
        "    y_min,\n",
        "    y_max,\n",
        "    t_min,\n",
        "    t_max,\n",
        "    mode=\"FNO\",\n",
        "    initial_step=None,\n",
        "):\n",
        "    if mode == \"Unet\":\n",
        "        with torch.no_grad():\n",
        "            for itot, (xx, yy) in enumerate(val_loader):\n",
        "                xx = xx.to(device)  # noqa: PLW2901\n",
        "                yy = yy.to(device)  # noqa: PLW2901\n",
        "\n",
        "                pred = yy[..., :initial_step, :]\n",
        "                inp_shape = list(xx.shape)\n",
        "                inp_shape = inp_shape[:-2]\n",
        "                inp_shape.append(-1)\n",
        "\n",
        "                for _t in range(initial_step, yy.shape[-2]):\n",
        "                    inp = xx.reshape(inp_shape)\n",
        "                    temp_shape = [0, -1]\n",
        "                    temp_shape.extend(list(range(1, len(inp.shape) - 1)))\n",
        "                    inp = inp.permute(temp_shape)\n",
        "\n",
        "                    temp_shape = [0]\n",
        "                    temp_shape.extend(list(range(2, len(inp.shape))))\n",
        "                    temp_shape.append(1)\n",
        "                    im = model(inp).permute(temp_shape).unsqueeze(-2)\n",
        "                    pred = torch.cat((pred, im), -2)\n",
        "                    xx = torch.cat((xx[..., 1:, :], im), dim=-2)  # noqa: PLW2901\n",
        "\n",
        "                (\n",
        "                    _err_RMSE,\n",
        "                    _err_nRMSE,\n",
        "                    _err_CSV,\n",
        "                    _err_Max,\n",
        "                    _err_BD,\n",
        "                    _err_F,\n",
        "                ) = metric_func(\n",
        "                    pred,\n",
        "                    yy,\n",
        "                    if_mean=True,\n",
        "                    Lx=Lx,\n",
        "                    Ly=Ly,\n",
        "                    Lz=Lz,\n",
        "                    initial_step=initial_step,\n",
        "                )\n",
        "\n",
        "                if itot == 0:\n",
        "                    err_RMSE, err_nRMSE, err_CSV, err_Max, err_BD, err_F = (\n",
        "                        _err_RMSE,\n",
        "                        _err_nRMSE,\n",
        "                        _err_CSV,\n",
        "                        _err_Max,\n",
        "                        _err_BD,\n",
        "                        _err_F,\n",
        "                    )\n",
        "                    pred_plot = pred[:1]\n",
        "                    target_plot = yy[:1]\n",
        "                    val_l2_time = torch.zeros(yy.shape[-2]).to(device)\n",
        "                else:\n",
        "                    err_RMSE += _err_RMSE\n",
        "                    err_nRMSE += _err_nRMSE\n",
        "                    err_CSV += _err_CSV\n",
        "                    err_Max += _err_Max\n",
        "                    err_BD += _err_BD\n",
        "                    err_F += _err_F\n",
        "\n",
        "                    mean_dim = list(range(len(yy.shape) - 2))\n",
        "                    mean_dim.append(-1)\n",
        "                    mean_dim = tuple(mean_dim)\n",
        "                    val_l2_time += torch.sqrt(\n",
        "                        torch.mean((pred - yy) ** 2, dim=mean_dim)\n",
        "                    )\n",
        "\n",
        "    elif mode == \"FNO\":\n",
        "        with torch.no_grad():\n",
        "            itot = 0\n",
        "            for itot, (xx, yy, grid) in enumerate(val_loader):\n",
        "                xx = xx.to(device)  # noqa: PLW2901\n",
        "                yy = yy.to(device)  # noqa: PLW2901\n",
        "                grid = grid.to(device)  # noqa: PLW2901\n",
        "\n",
        "                pred = yy[..., :initial_step, :]\n",
        "                inp_shape = list(xx.shape)\n",
        "                inp_shape = inp_shape[:-2]\n",
        "                inp_shape.append(-1)\n",
        "\n",
        "                for _t in range(initial_step, yy.shape[-2]):\n",
        "                    inp = xx.reshape(inp_shape)\n",
        "                    im = model(inp, grid)\n",
        "                    pred = torch.cat((pred, im), -2)\n",
        "                    xx = torch.cat((xx[..., 1:, :], im), dim=-2)  # noqa: PLW2901\n",
        "\n",
        "                (\n",
        "                    _err_RMSE,\n",
        "                    _err_nRMSE,\n",
        "                    _err_CSV,\n",
        "                    _err_Max,\n",
        "                    _err_BD,\n",
        "                    _err_F,\n",
        "                ) = metric_func(\n",
        "                    pred,\n",
        "                    yy,\n",
        "                    if_mean=True,\n",
        "                    Lx=Lx,\n",
        "                    Ly=Ly,\n",
        "                    Lz=Lz,\n",
        "                    initial_step=initial_step,\n",
        "                )\n",
        "                if itot == 0:\n",
        "                    err_RMSE, err_nRMSE, err_CSV, err_Max, err_BD, err_F = (\n",
        "                        _err_RMSE,\n",
        "                        _err_nRMSE,\n",
        "                        _err_CSV,\n",
        "                        _err_Max,\n",
        "                        _err_BD,\n",
        "                        _err_F,\n",
        "                    )\n",
        "                    pred_plot = pred[:1]\n",
        "                    target_plot = yy[:1]\n",
        "                    val_l2_time = torch.zeros(yy.shape[-2]).to(device)\n",
        "                else:\n",
        "                    err_RMSE += _err_RMSE\n",
        "                    err_nRMSE += _err_nRMSE\n",
        "                    err_CSV += _err_CSV\n",
        "                    err_Max += _err_Max\n",
        "                    err_BD += _err_BD\n",
        "                    err_F += _err_F\n",
        "\n",
        "                    mean_dim = list(range(len(yy.shape) - 2))\n",
        "                    mean_dim.append(-1)\n",
        "                    mean_dim = tuple(mean_dim)\n",
        "                    val_l2_time += torch.sqrt(\n",
        "                        torch.mean((pred - yy) ** 2, dim=mean_dim)\n",
        "                    )\n",
        "\n",
        "    elif mode == \"PINN\":\n",
        "        raise NotImplementedError\n",
        "\n",
        "    err_RMSE = np.array(err_RMSE.data.cpu() / itot)\n",
        "    err_nRMSE = np.array(err_nRMSE.data.cpu() / itot)\n",
        "    err_CSV = np.array(err_CSV.data.cpu() / itot)\n",
        "    err_Max = np.array(err_Max.data.cpu() / itot)\n",
        "    err_BD = np.array(err_BD.data.cpu() / itot)\n",
        "    err_F = np.array(err_F.data.cpu() / itot)\n",
        "    logger.info(f\"RMSE: {err_RMSE:.5f}\")\n",
        "    logger.info(f\"normalized RMSE: {err_nRMSE:.5f}\")\n",
        "    logger.info(f\"RMSE of conserved variables: {err_CSV:.5f}\")\n",
        "    logger.info(f\"Maximum value of rms error: {err_Max:.5f}\")\n",
        "    logger.info(f\"RMSE at boundaries: {err_BD:.5f}\")\n",
        "    logger.info(f\"RMSE in Fourier space: {err_F}\")\n",
        "\n",
        "    val_l2_time = val_l2_time / itot\n",
        "\n",
        "    if plot:\n",
        "        dim = len(yy.shape) - 3\n",
        "        plt.ioff()\n",
        "        if dim == 1:\n",
        "            fig, ax = plt.subplots(figsize=(6.5, 6))\n",
        "            h = ax.imshow(\n",
        "                pred_plot[..., channel_plot].squeeze().detach().cpu(),\n",
        "                extent=[t_min, t_max, x_min, x_max],\n",
        "                origin=\"lower\",\n",
        "                aspect=\"auto\",\n",
        "            )\n",
        "            h.set_clim(\n",
        "                target_plot[..., channel_plot].min(),\n",
        "                target_plot[..., channel_plot].max(),\n",
        "            )\n",
        "            divider = make_axes_locatable(ax)\n",
        "            cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "            cbar = fig.colorbar(h, cax=cax)\n",
        "            cbar.ax.tick_params(labelsize=30)\n",
        "            ax.set_title(\"Prediction\", fontsize=30)\n",
        "            ax.tick_params(axis=\"x\", labelsize=30)\n",
        "            ax.tick_params(axis=\"y\", labelsize=30)\n",
        "            ax.set_ylabel(\"$x$\", fontsize=30)\n",
        "            ax.set_xlabel(\"$t$\", fontsize=30)\n",
        "            plt.tight_layout()\n",
        "            filename = model_name + \"_pred.pdf\"\n",
        "            plt.savefig(filename)\n",
        "\n",
        "            fig, ax = plt.subplots(figsize=(6.5, 6))\n",
        "            h = ax.imshow(\n",
        "                target_plot[..., channel_plot].squeeze().detach().cpu(),\n",
        "                extent=[t_min, t_max, x_min, x_max],\n",
        "                origin=\"lower\",\n",
        "                aspect=\"auto\",\n",
        "            )\n",
        "            h.set_clim(\n",
        "                target_plot[..., channel_plot].min(),\n",
        "                target_plot[..., channel_plot].max(),\n",
        "            )\n",
        "            divider = make_axes_locatable(ax)\n",
        "            cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "            cbar = fig.colorbar(h, cax=cax)\n",
        "            cbar.ax.tick_params(labelsize=30)\n",
        "            ax.set_title(\"Data\", fontsize=30)\n",
        "            ax.tick_params(axis=\"x\", labelsize=30)\n",
        "            ax.tick_params(axis=\"y\", labelsize=30)\n",
        "            ax.set_ylabel(\"$x$\", fontsize=30)\n",
        "            ax.set_xlabel(\"$t$\", fontsize=30)\n",
        "            plt.tight_layout()\n",
        "            filename = model_name + \"_data.pdf\"\n",
        "            plt.savefig(filename)\n",
        "\n",
        "        elif dim == 2:\n",
        "            fig, ax = plt.subplots(figsize=(6.5, 6))\n",
        "            h = ax.imshow(\n",
        "                pred_plot[..., -1, channel_plot].squeeze().t().detach().cpu(),\n",
        "                extent=[x_min, x_max, y_min, y_max],\n",
        "                origin=\"lower\",\n",
        "                aspect=\"auto\",\n",
        "            )\n",
        "            h.set_clim(\n",
        "                target_plot[..., -1, channel_plot].min(),\n",
        "                target_plot[..., -1, channel_plot].max(),\n",
        "            )\n",
        "            divider = make_axes_locatable(ax)\n",
        "            cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "            cbar = fig.colorbar(h, cax=cax)\n",
        "            cbar.ax.tick_params(labelsize=30)\n",
        "            ax.set_title(\"Prediction\", fontsize=30)\n",
        "            ax.tick_params(axis=\"x\", labelsize=30)\n",
        "            ax.tick_params(axis=\"y\", labelsize=30)\n",
        "            ax.set_ylabel(\"$y$\", fontsize=30)\n",
        "            ax.set_xlabel(\"$x$\", fontsize=30)\n",
        "            plt.tight_layout()\n",
        "            filename = model_name + \"_pred.pdf\"\n",
        "            plt.savefig(filename)\n",
        "\n",
        "            fig, ax = plt.subplots(figsize=(6.5, 6))\n",
        "            h = ax.imshow(\n",
        "                target_plot[..., -1, channel_plot].squeeze().t().detach().cpu(),\n",
        "                extent=[x_min, x_max, y_min, y_max],\n",
        "                origin=\"lower\",\n",
        "                aspect=\"auto\",\n",
        "            )\n",
        "            h.set_clim(\n",
        "                target_plot[..., -1, channel_plot].min(),\n",
        "                target_plot[..., -1, channel_plot].max(),\n",
        "            )\n",
        "            divider = make_axes_locatable(ax)\n",
        "            cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "            cbar = fig.colorbar(h, cax=cax)\n",
        "            cbar.ax.tick_params(labelsize=30)\n",
        "            ax.set_title(\"Data\", fontsize=30)\n",
        "            ax.tick_params(axis=\"x\", labelsize=30)\n",
        "            ax.tick_params(axis=\"y\", labelsize=30)\n",
        "            ax.set_ylabel(\"$y$\", fontsize=30)\n",
        "            ax.set_xlabel(\"$x$\", fontsize=30)\n",
        "            plt.tight_layout()\n",
        "            filename = model_name + \"_data.pdf\"\n",
        "            plt.savefig(filename)\n",
        "\n",
        "        # plt.figure(figsize=(8,8))\n",
        "        # plt.semilogy(torch.arange(initial_step,yy.shape[-2]),\n",
        "        #              val_l2_time[initial_step:].detach().cpu())\n",
        "        # plt.xlabel('$t$', fontsize=30)\n",
        "        # plt.ylabel('$MSE$', fontsize=30)\n",
        "        # plt.title('MSE vs unrolled time steps', fontsize=30)\n",
        "        # plt.tight_layout()\n",
        "        # filename = model_name + '_mse_time.pdf'\n",
        "        # plt.savefig(filename)\n",
        "\n",
        "        filename = model_name + \"mse_time.npz\"\n",
        "        np.savez(\n",
        "            filename,\n",
        "            t=torch.arange(initial_step, yy.shape[-2]).cpu(),\n",
        "            mse=val_l2_time[initial_step:].detach().cpu(),\n",
        "        )\n",
        "\n",
        "    return err_RMSE, err_nRMSE, err_CSV, err_Max, err_BD, err_F"
      ],
      "metadata": {
        "id": "AuiRt2x4xiGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# -------------------- Configuration --------------------\n",
        "filename = \"1D_Advection_Sols_beta0.1_reduced.hdf5\"\n",
        "base_path = \"/content/drive/MyDrive/\"\n",
        "\n",
        "# Training settings\n",
        "if_training = True\n",
        "continue_training = False\n",
        "num_workers = 0\n",
        "batch_size = 50\n",
        "initial_step = 10\n",
        "t_train = 200\n",
        "epochs = 500\n",
        "learning_rate = 1e-3\n",
        "scheduler_step = 100\n",
        "scheduler_gamma = 0.5\n",
        "model_update = 1\n",
        "\n",
        "# FNO model parameters\n",
        "num_channels = 1\n",
        "modes = 12\n",
        "width = 20\n",
        "\n",
        "N_layers = 4\n",
        "N_res    = 4\n",
        "N_res_neck = 4\n",
        "channel_multiplier = 16\n",
        "\n",
        "# Dataset preprocessing options\n",
        "single_file = True\n",
        "reduced_resolution = 1\n",
        "reduced_resolution_t = 1\n",
        "reduced_batch = 1\n",
        "\n",
        "# Plotting and bounds\n",
        "plot = True\n",
        "channel_plot = True\n",
        "x_min, x_max = 0.0, 1.0\n",
        "y_min, y_max = 0.0, 1.0\n",
        "t_min, t_max = 0.0, 1.0\n",
        "\n",
        "training_type = \"autoregressive\""
      ],
      "metadata": {
        "id": "2o1xUUx_xiDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bmq7sNOAao_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- Load Data --------------------\n",
        "model_name = filename[:-5] + \"_FNO\"\n",
        "model_path = model_name + \".pt\""
      ],
      "metadata": {
        "id": "5toD_OePxiAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = FNODatasetSingle(\n",
        "    filename,\n",
        "    reduced_resolution=reduced_resolution,\n",
        "    reduced_resolution_t=reduced_resolution_t,\n",
        "    reduced_batch=reduced_batch,\n",
        "    initial_step=initial_step,\n",
        "    saved_folder=base_path,\n",
        ")"
      ],
      "metadata": {
        "id": "QUpLs_GWxh9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_data = FNODatasetSingle(\n",
        "    filename,\n",
        "    reduced_resolution=reduced_resolution,\n",
        "    reduced_resolution_t=reduced_resolution_t,\n",
        "    reduced_batch=reduced_batch,\n",
        "    initial_step=initial_step,\n",
        "    if_test=True,\n",
        "    saved_folder=base_path,\n",
        ")"
      ],
      "metadata": {
        "id": "99mOgcNPxh6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, num_workers=num_workers, shuffle=False)"
      ],
      "metadata": {
        "id": "_2ug0THbxh30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, _data, _ = next(iter(val_loader))\n",
        "t_train = min(t_train, _data.shape[-2])"
      ],
      "metadata": {
        "id": "MNVGIPsV0QFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = FNO1d(\n",
        "    num_channels=num_channels,\n",
        "    width=width,\n",
        "    modes=modes,\n",
        "    initial_step=initial_step,\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "2uzp8r400QDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=scheduler_step, gamma=scheduler_gamma)\n",
        "loss_fn = nn.MSELoss(reduction=\"mean\")\n",
        "loss_val_min = np.inf\n",
        "start_epoch = 0"
      ],
      "metadata": {
        "id": "2E_XrgIP0QAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ep in range(start_epoch, epochs):\n",
        "    model.train()\n",
        "    t1 = default_timer()\n",
        "    train_l2_step, train_l2_full = 0, 0\n",
        "\n",
        "    for xx, yy, grid in train_loader:\n",
        "        loss = 0\n",
        "        xx, yy, grid = xx.to(device), yy.to(device), grid.to(device)\n",
        "        pred = yy[..., :initial_step, :]\n",
        "        inp_shape = list(xx.shape[:-2]) + [-1]\n",
        "\n",
        "        for t in range(initial_step, t_train):\n",
        "            inp = xx.reshape(inp_shape)\n",
        "            y = yy[..., t : t + 1, :]\n",
        "            im = model(inp, grid)\n",
        "            _batch = im.size(0)\n",
        "            loss += loss_fn(im.reshape(_batch, -1), y.reshape(_batch, -1))\n",
        "            pred = torch.cat((pred, im), -2)\n",
        "            xx = torch.cat((xx[..., 1:, :], im), dim=-2)\n",
        "\n",
        "        train_l2_step += loss.item()\n",
        "        _batch = yy.size(0)\n",
        "        _yy = yy[..., :t_train, :]\n",
        "        l2_full = loss_fn(pred.reshape(_batch, -1), _yy.reshape(_batch, -1))\n",
        "        train_l2_full += l2_full.item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if ep % model_update == 0:\n",
        "        val_l2_step, val_l2_full = 0, 0\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for xx, yy, grid in val_loader:\n",
        "                loss = 0\n",
        "                xx, yy, grid = xx.to(device), yy.to(device), grid.to(device)\n",
        "                pred = yy[..., :initial_step, :]\n",
        "                inp_shape = list(xx.shape[:-2]) + [-1]\n",
        "\n",
        "                for t in range(initial_step, yy.shape[-2]):\n",
        "                    inp = xx.reshape(inp_shape)\n",
        "                    y = yy[..., t : t + 1, :]\n",
        "                    im = model(inp, grid)\n",
        "                    _batch = im.size(0)\n",
        "                    loss += loss_fn(im.reshape(_batch, -1), y.reshape(_batch, -1))\n",
        "                    pred = torch.cat((pred, im), -2)\n",
        "                    xx = torch.cat((xx[..., 1:, :], im), dim=-2)\n",
        "\n",
        "                val_l2_step += loss.item()\n",
        "                _pred = pred[..., initial_step:t_train, :]\n",
        "                _yy = yy[..., initial_step:t_train, :]\n",
        "                val_l2_full += loss_fn(_pred.reshape(_batch, -1), _yy.reshape(_batch, -1)).item()\n",
        "\n",
        "            if val_l2_full < loss_val_min:\n",
        "                loss_val_min = val_l2_full\n",
        "                torch.save(\n",
        "                    {\n",
        "                        \"epoch\": ep,\n",
        "                        \"model_state_dict\": model.state_dict(),\n",
        "                        \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "                        \"loss\": loss_val_min,\n",
        "                    },\n",
        "                    model_path,\n",
        "                )\n",
        "    t2 = default_timer()\n",
        "    scheduler.step()\n",
        "    print(\"epoch: {0}, loss: {1:.5f}, t2-t1: {2:.5f}, trainL2: {3:.5f}, testL2: {4:.5f}\".format(ep, loss.item(), t2 - t1, train_l2_full, val_l2_full))\n",
        "\n",
        "print(\"Training complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qx6NTS8I0P-C",
        "outputId": "f6c52195-4267-4a4a-dca3-d03e310bfed1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, loss: 0.07390, t2-t1: 39.82128, trainL2: 14.83780, testL2: 0.04598\n",
            "epoch: 1, loss: 0.04386, t2-t1: 37.53585, trainL2: 0.23311, testL2: 0.02793\n",
            "epoch: 2, loss: 0.03394, t2-t1: 39.87717, trainL2: 0.16751, testL2: 0.02176\n",
            "epoch: 3, loss: 0.03089, t2-t1: 37.49741, trainL2: 0.13998, testL2: 0.01925\n",
            "epoch: 4, loss: 0.02565, t2-t1: 37.52052, trainL2: 0.11707, testL2: 0.01595\n",
            "epoch: 5, loss: 0.02725, t2-t1: 37.50794, trainL2: 0.11484, testL2: 0.01648\n",
            "epoch: 6, loss: 0.02504, t2-t1: 37.14256, trainL2: 0.11605, testL2: 0.01477\n",
            "epoch: 7, loss: 0.04539, t2-t1: 37.36807, trainL2: 0.13849, testL2: 0.02435\n",
            "epoch: 8, loss: 0.02738, t2-t1: 38.31197, trainL2: 0.20923, testL2: 0.01726\n",
            "epoch: 9, loss: 0.04240, t2-t1: 37.46873, trainL2: 0.08299, testL2: 0.02978\n",
            "epoch: 10, loss: 0.01879, t2-t1: 37.38861, trainL2: 0.07575, testL2: 0.01060\n",
            "epoch: 11, loss: 0.02050, t2-t1: 37.58353, trainL2: 0.07073, testL2: 0.01180\n",
            "epoch: 12, loss: 0.03899, t2-t1: 37.46557, trainL2: 0.12429, testL2: 0.02307\n",
            "epoch: 13, loss: 0.01791, t2-t1: 37.59177, trainL2: 0.09708, testL2: 0.01042\n",
            "epoch: 14, loss: 0.02383, t2-t1: 38.44198, trainL2: 0.06635, testL2: 0.01469\n",
            "epoch: 15, loss: 0.01804, t2-t1: 37.35323, trainL2: 0.11255, testL2: 0.01047\n",
            "epoch: 16, loss: 0.02336, t2-t1: 37.64970, trainL2: 0.09546, testL2: 0.01283\n",
            "epoch: 17, loss: 0.01933, t2-t1: 37.41521, trainL2: 0.07989, testL2: 0.01183\n",
            "epoch: 18, loss: 0.01752, t2-t1: 37.02065, trainL2: 0.14109, testL2: 0.01007\n",
            "epoch: 19, loss: 0.05022, t2-t1: 36.94277, trainL2: 0.08921, testL2: 0.03026\n",
            "epoch: 20, loss: 0.02063, t2-t1: 38.30379, trainL2: 0.09551, testL2: 0.01107\n",
            "epoch: 21, loss: 0.02409, t2-t1: 37.46012, trainL2: 0.09290, testL2: 0.01425\n",
            "epoch: 22, loss: 0.03320, t2-t1: 37.38422, trainL2: 0.13849, testL2: 0.01900\n",
            "epoch: 23, loss: 0.01631, t2-t1: 37.53851, trainL2: 0.06376, testL2: 0.00915\n",
            "epoch: 24, loss: 0.01808, t2-t1: 37.52701, trainL2: 0.05707, testL2: 0.01047\n",
            "epoch: 25, loss: 0.01884, t2-t1: 37.33399, trainL2: 0.21927, testL2: 0.01065\n",
            "epoch: 26, loss: 0.01598, t2-t1: 38.56878, trainL2: 0.05778, testL2: 0.00895\n",
            "epoch: 27, loss: 0.01658, t2-t1: 37.39573, trainL2: 0.05716, testL2: 0.00935\n",
            "epoch: 28, loss: 0.02157, t2-t1: 37.23244, trainL2: 0.06383, testL2: 0.01272\n",
            "epoch: 29, loss: 0.04110, t2-t1: 36.91415, trainL2: 0.09363, testL2: 0.02517\n",
            "epoch: 30, loss: 0.01677, t2-t1: 37.20476, trainL2: 0.13231, testL2: 0.00952\n",
            "epoch: 31, loss: 0.01620, t2-t1: 37.35424, trainL2: 0.06439, testL2: 0.00907\n",
            "epoch: 32, loss: 0.01618, t2-t1: 38.00812, trainL2: 0.06461, testL2: 0.00918\n",
            "epoch: 33, loss: 0.01601, t2-t1: 37.76875, trainL2: 0.05932, testL2: 0.00907\n",
            "epoch: 34, loss: 0.01722, t2-t1: 37.31073, trainL2: 0.06372, testL2: 0.01004\n",
            "epoch: 35, loss: 0.01839, t2-t1: 38.44049, trainL2: 0.12636, testL2: 0.01062\n",
            "epoch: 36, loss: 0.01570, t2-t1: 38.30224, trainL2: 0.06322, testL2: 0.00881\n",
            "epoch: 37, loss: 0.01706, t2-t1: 37.88879, trainL2: 0.05861, testL2: 0.00942\n",
            "epoch: 38, loss: 0.06898, t2-t1: 39.23430, trainL2: 0.17066, testL2: 0.03924\n",
            "epoch: 39, loss: 0.01685, t2-t1: 38.09154, trainL2: 0.11933, testL2: 0.00950\n",
            "epoch: 40, loss: 0.01544, t2-t1: 37.98288, trainL2: 0.05453, testL2: 0.00865\n",
            "epoch: 41, loss: 0.01534, t2-t1: 38.01876, trainL2: 0.05348, testL2: 0.00863\n",
            "epoch: 42, loss: 0.01551, t2-t1: 38.13189, trainL2: 0.05290, testL2: 0.00873\n",
            "epoch: 43, loss: 0.01758, t2-t1: 37.98276, trainL2: 0.05670, testL2: 0.00972\n",
            "epoch: 44, loss: 0.02092, t2-t1: 39.02225, trainL2: 0.06998, testL2: 0.01311\n",
            "epoch: 45, loss: 0.02132, t2-t1: 37.86762, trainL2: 0.07114, testL2: 0.01202\n",
            "epoch: 46, loss: 0.01531, t2-t1: 37.10733, trainL2: 0.06926, testL2: 0.00861\n",
            "epoch: 47, loss: 0.01799, t2-t1: 36.98151, trainL2: 0.07962, testL2: 0.01039\n",
            "epoch: 48, loss: 0.01647, t2-t1: 37.72297, trainL2: 0.12568, testL2: 0.00926\n",
            "epoch: 49, loss: 0.01612, t2-t1: 37.61715, trainL2: 0.08894, testL2: 0.00922\n",
            "epoch: 50, loss: 0.01482, t2-t1: 38.28693, trainL2: 0.05360, testL2: 0.00830\n",
            "epoch: 51, loss: 0.01545, t2-t1: 37.52710, trainL2: 0.05192, testL2: 0.00843\n",
            "epoch: 52, loss: 0.02282, t2-t1: 37.62623, trainL2: 0.06052, testL2: 0.01181\n",
            "epoch: 53, loss: 0.01562, t2-t1: 37.42754, trainL2: 0.06542, testL2: 0.00866\n",
            "epoch: 54, loss: 0.02914, t2-t1: 37.32052, trainL2: 0.08659, testL2: 0.01895\n",
            "epoch: 55, loss: 0.01766, t2-t1: 37.44221, trainL2: 0.08720, testL2: 0.01077\n",
            "epoch: 56, loss: 0.01450, t2-t1: 37.62173, trainL2: 0.06066, testL2: 0.00820\n",
            "epoch: 57, loss: 0.01455, t2-t1: 38.72481, trainL2: 0.05297, testL2: 0.00834\n",
            "epoch: 58, loss: 0.01961, t2-t1: 37.15490, trainL2: 0.09860, testL2: 0.01102\n",
            "epoch: 59, loss: 0.01755, t2-t1: 37.18396, trainL2: 0.05900, testL2: 0.01005\n",
            "epoch: 60, loss: 0.01438, t2-t1: 37.14916, trainL2: 0.05811, testL2: 0.00801\n",
            "epoch: 61, loss: 0.01749, t2-t1: 37.39853, trainL2: 0.05314, testL2: 0.00955\n",
            "epoch: 62, loss: 0.01500, t2-t1: 37.34489, trainL2: 0.10111, testL2: 0.00861\n",
            "epoch: 63, loss: 0.01641, t2-t1: 38.56038, trainL2: 0.05698, testL2: 0.00925\n",
            "epoch: 64, loss: 0.01743, t2-t1: 37.52739, trainL2: 0.05817, testL2: 0.01003\n",
            "epoch: 65, loss: 0.01822, t2-t1: 37.62113, trainL2: 0.06110, testL2: 0.01103\n",
            "epoch: 66, loss: 0.02304, t2-t1: 37.10501, trainL2: 0.07227, testL2: 0.01471\n",
            "epoch: 67, loss: 0.01482, t2-t1: 37.91177, trainL2: 0.06475, testL2: 0.00828\n",
            "epoch: 68, loss: 0.01371, t2-t1: 38.73325, trainL2: 0.05410, testL2: 0.00768\n",
            "epoch: 69, loss: 0.01400, t2-t1: 37.77527, trainL2: 0.04960, testL2: 0.00778\n",
            "epoch: 70, loss: 0.02179, t2-t1: 37.25962, trainL2: 0.07239, testL2: 0.01243\n",
            "epoch: 71, loss: 0.01373, t2-t1: 37.63285, trainL2: 0.06675, testL2: 0.00772\n",
            "epoch: 72, loss: 0.01671, t2-t1: 38.06356, trainL2: 0.06160, testL2: 0.00930\n",
            "epoch: 73, loss: 0.01340, t2-t1: 37.99016, trainL2: 0.07668, testL2: 0.00756\n",
            "epoch: 74, loss: 0.01938, t2-t1: 37.80003, trainL2: 0.04951, testL2: 0.01180\n",
            "epoch: 75, loss: 0.01359, t2-t1: 39.21293, trainL2: 0.05504, testL2: 0.00749\n",
            "epoch: 76, loss: 0.02513, t2-t1: 37.86373, trainL2: 0.11408, testL2: 0.01489\n",
            "epoch: 77, loss: 0.01349, t2-t1: 37.81103, trainL2: 0.07505, testL2: 0.00749\n",
            "epoch: 78, loss: 0.01273, t2-t1: 37.77032, trainL2: 0.04593, testL2: 0.00713\n",
            "epoch: 79, loss: 0.01374, t2-t1: 37.75609, trainL2: 0.04582, testL2: 0.00754\n",
            "epoch: 80, loss: 0.01337, t2-t1: 38.90081, trainL2: 0.05016, testL2: 0.00743\n",
            "epoch: 81, loss: 0.01306, t2-t1: 38.20732, trainL2: 0.04686, testL2: 0.00747\n",
            "epoch: 82, loss: 0.03286, t2-t1: 38.29273, trainL2: 0.07149, testL2: 0.02033\n",
            "epoch: 83, loss: 0.01221, t2-t1: 37.92944, trainL2: 0.06820, testL2: 0.00694\n",
            "epoch: 84, loss: 0.01542, t2-t1: 37.73126, trainL2: 0.04725, testL2: 0.00889\n",
            "epoch: 85, loss: 0.01219, t2-t1: 37.83385, trainL2: 0.05561, testL2: 0.00698\n",
            "epoch: 86, loss: 0.01326, t2-t1: 38.61305, trainL2: 0.04636, testL2: 0.00740\n",
            "epoch: 87, loss: 0.01306, t2-t1: 37.55122, trainL2: 0.04883, testL2: 0.00745\n",
            "epoch: 88, loss: 0.01216, t2-t1: 37.77951, trainL2: 0.08367, testL2: 0.00703\n",
            "epoch: 89, loss: 0.01263, t2-t1: 37.78179, trainL2: 0.04569, testL2: 0.00706\n",
            "epoch: 90, loss: 0.01310, t2-t1: 37.63292, trainL2: 0.09894, testL2: 0.00732\n",
            "epoch: 91, loss: 0.01132, t2-t1: 37.65403, trainL2: 0.04162, testL2: 0.00658\n",
            "epoch: 92, loss: 0.01125, t2-t1: 38.96642, trainL2: 0.04132, testL2: 0.00642\n",
            "epoch: 93, loss: 0.01184, t2-t1: 38.11859, trainL2: 0.04240, testL2: 0.00682\n",
            "epoch: 94, loss: 0.01129, t2-t1: 38.00096, trainL2: 0.04506, testL2: 0.00635\n",
            "epoch: 95, loss: 0.01373, t2-t1: 37.94945, trainL2: 0.05426, testL2: 0.00831\n",
            "epoch: 96, loss: 0.01058, t2-t1: 37.73005, trainL2: 0.07248, testL2: 0.00612\n",
            "epoch: 97, loss: 0.01879, t2-t1: 38.46893, trainL2: 0.06083, testL2: 0.01124\n",
            "epoch: 98, loss: 0.01034, t2-t1: 38.34687, trainL2: 0.04358, testL2: 0.00604\n",
            "epoch: 99, loss: 0.01270, t2-t1: 37.89218, trainL2: 0.06822, testL2: 0.00767\n",
            "epoch: 100, loss: 0.00985, t2-t1: 37.85247, trainL2: 0.03849, testL2: 0.00580\n",
            "epoch: 101, loss: 0.00980, t2-t1: 38.12714, trainL2: 0.03724, testL2: 0.00578\n",
            "epoch: 102, loss: 0.00967, t2-t1: 38.31548, trainL2: 0.03687, testL2: 0.00572\n",
            "epoch: 103, loss: 0.00958, t2-t1: 38.69854, trainL2: 0.03681, testL2: 0.00569\n",
            "epoch: 104, loss: 0.00964, t2-t1: 39.14891, trainL2: 0.03649, testL2: 0.00569\n",
            "epoch: 105, loss: 0.00968, t2-t1: 38.34978, trainL2: 0.03628, testL2: 0.00572\n",
            "epoch: 106, loss: 0.00943, t2-t1: 38.28781, trainL2: 0.03666, testL2: 0.00557\n",
            "epoch: 107, loss: 0.00921, t2-t1: 37.76356, trainL2: 0.03570, testL2: 0.00550\n",
            "epoch: 108, loss: 0.00912, t2-t1: 37.63648, trainL2: 0.03604, testL2: 0.00549\n",
            "epoch: 109, loss: 0.00977, t2-t1: 37.58526, trainL2: 0.04420, testL2: 0.00584\n",
            "epoch: 110, loss: 0.00895, t2-t1: 38.73238, trainL2: 0.03662, testL2: 0.00540\n",
            "epoch: 111, loss: 0.00897, t2-t1: 37.79231, trainL2: 0.03815, testL2: 0.00542\n",
            "epoch: 112, loss: 0.00905, t2-t1: 37.71813, trainL2: 0.03921, testL2: 0.00535\n",
            "epoch: 113, loss: 0.00879, t2-t1: 37.59556, trainL2: 0.03650, testL2: 0.00536\n",
            "epoch: 114, loss: 0.00923, t2-t1: 37.67709, trainL2: 0.03440, testL2: 0.00570\n",
            "epoch: 115, loss: 0.00932, t2-t1: 37.71220, trainL2: 0.03734, testL2: 0.00565\n",
            "epoch: 116, loss: 0.00807, t2-t1: 38.76197, trainL2: 0.03989, testL2: 0.00480\n",
            "epoch: 117, loss: 0.00802, t2-t1: 37.41972, trainL2: 0.03165, testL2: 0.00483\n",
            "epoch: 118, loss: 0.01065, t2-t1: 37.71018, trainL2: 0.04186, testL2: 0.00641\n",
            "epoch: 119, loss: 0.00783, t2-t1: 37.86999, trainL2: 0.03203, testL2: 0.00475\n",
            "epoch: 120, loss: 0.00792, t2-t1: 38.43956, trainL2: 0.03148, testL2: 0.00482\n",
            "epoch: 121, loss: 0.00774, t2-t1: 38.20259, trainL2: 0.03090, testL2: 0.00473\n",
            "epoch: 122, loss: 0.00787, t2-t1: 38.83969, trainL2: 0.03343, testL2: 0.00474\n",
            "epoch: 123, loss: 0.00759, t2-t1: 37.97629, trainL2: 0.03226, testL2: 0.00459\n",
            "epoch: 124, loss: 0.01574, t2-t1: 37.90892, trainL2: 0.04042, testL2: 0.00812\n",
            "epoch: 125, loss: 0.00790, t2-t1: 37.51388, trainL2: 0.03444, testL2: 0.00469\n",
            "epoch: 126, loss: 0.00773, t2-t1: 37.18749, trainL2: 0.03007, testL2: 0.00473\n",
            "epoch: 127, loss: 0.00824, t2-t1: 38.58147, trainL2: 0.03185, testL2: 0.00486\n",
            "epoch: 128, loss: 0.00822, t2-t1: 37.40999, trainL2: 0.03074, testL2: 0.00496\n",
            "epoch: 129, loss: 0.00977, t2-t1: 37.32710, trainL2: 0.04944, testL2: 0.00607\n",
            "epoch: 130, loss: 0.00738, t2-t1: 37.56026, trainL2: 0.03117, testL2: 0.00446\n",
            "epoch: 131, loss: 0.00731, t2-t1: 37.86573, trainL2: 0.02943, testL2: 0.00440\n",
            "epoch: 132, loss: 0.00764, t2-t1: 37.97307, trainL2: 0.02927, testL2: 0.00457\n",
            "epoch: 133, loss: 0.00798, t2-t1: 39.04535, trainL2: 0.03200, testL2: 0.00485\n",
            "epoch: 134, loss: 0.00811, t2-t1: 38.10503, trainL2: 0.03148, testL2: 0.00476\n",
            "epoch: 135, loss: 0.01500, t2-t1: 38.09581, trainL2: 0.03266, testL2: 0.00907\n",
            "epoch: 136, loss: 0.00718, t2-t1: 37.60502, trainL2: 0.03999, testL2: 0.00436\n",
            "epoch: 137, loss: 0.00740, t2-t1: 37.62776, trainL2: 0.02881, testL2: 0.00447\n",
            "epoch: 138, loss: 0.00730, t2-t1: 37.44415, trainL2: 0.03067, testL2: 0.00439\n",
            "epoch: 139, loss: 0.00707, t2-t1: 38.38490, trainL2: 0.02926, testL2: 0.00430\n",
            "epoch: 140, loss: 0.00863, t2-t1: 37.37182, trainL2: 0.03908, testL2: 0.00500\n",
            "epoch: 141, loss: 0.00705, t2-t1: 36.96045, trainL2: 0.03049, testL2: 0.00431\n",
            "epoch: 142, loss: 0.00703, t2-t1: 37.25055, trainL2: 0.02866, testL2: 0.00426\n",
            "epoch: 143, loss: 0.00732, t2-t1: 37.82672, trainL2: 0.02917, testL2: 0.00445\n",
            "epoch: 144, loss: 0.00813, t2-t1: 37.96437, trainL2: 0.04058, testL2: 0.00473\n",
            "epoch: 145, loss: 0.00704, t2-t1: 39.16529, trainL2: 0.02962, testL2: 0.00427\n",
            "epoch: 146, loss: 0.00701, t2-t1: 38.10014, trainL2: 0.02900, testL2: 0.00423\n",
            "epoch: 147, loss: 0.00686, t2-t1: 38.36665, trainL2: 0.03621, testL2: 0.00417\n",
            "epoch: 148, loss: 0.00991, t2-t1: 38.12777, trainL2: 0.03136, testL2: 0.00555\n",
            "epoch: 149, loss: 0.00711, t2-t1: 38.09970, trainL2: 0.03228, testL2: 0.00422\n",
            "epoch: 150, loss: 0.00714, t2-t1: 38.95292, trainL2: 0.02868, testL2: 0.00422\n",
            "epoch: 151, loss: 0.00728, t2-t1: 37.97900, trainL2: 0.02905, testL2: 0.00425\n",
            "epoch: 152, loss: 0.00762, t2-t1: 37.88902, trainL2: 0.03170, testL2: 0.00455\n",
            "epoch: 153, loss: 0.00716, t2-t1: 37.90958, trainL2: 0.02883, testL2: 0.00428\n",
            "epoch: 154, loss: 0.01211, t2-t1: 37.88540, trainL2: 0.04092, testL2: 0.00737\n",
            "epoch: 155, loss: 0.00679, t2-t1: 37.62960, trainL2: 0.03368, testL2: 0.00411\n",
            "epoch: 156, loss: 0.00677, t2-t1: 38.70305, trainL2: 0.02740, testL2: 0.00409\n",
            "epoch: 157, loss: 0.00690, t2-t1: 37.58425, trainL2: 0.02719, testL2: 0.00411\n",
            "epoch: 158, loss: 0.00818, t2-t1: 37.49096, trainL2: 0.02866, testL2: 0.00488\n",
            "epoch: 159, loss: 0.00703, t2-t1: 37.10757, trainL2: 0.03294, testL2: 0.00416\n",
            "epoch: 160, loss: 0.00687, t2-t1: 37.10154, trainL2: 0.02768, testL2: 0.00414\n",
            "epoch: 161, loss: 0.00789, t2-t1: 37.47812, trainL2: 0.02853, testL2: 0.00504\n",
            "epoch: 162, loss: 0.00710, t2-t1: 38.53560, trainL2: 0.03730, testL2: 0.00415\n",
            "epoch: 163, loss: 0.00700, t2-t1: 37.81379, trainL2: 0.02771, testL2: 0.00412\n",
            "epoch: 164, loss: 0.00657, t2-t1: 37.89609, trainL2: 0.02735, testL2: 0.00399\n",
            "epoch: 165, loss: 0.00711, t2-t1: 38.09424, trainL2: 0.03424, testL2: 0.00411\n",
            "epoch: 166, loss: 0.00695, t2-t1: 37.90646, trainL2: 0.02848, testL2: 0.00404\n",
            "epoch: 167, loss: 0.00756, t2-t1: 38.16732, trainL2: 0.03036, testL2: 0.00449\n",
            "epoch: 168, loss: 0.00753, t2-t1: 38.70848, trainL2: 0.03105, testL2: 0.00441\n",
            "epoch: 169, loss: 0.00877, t2-t1: 37.87170, trainL2: 0.03189, testL2: 0.00492\n",
            "epoch: 170, loss: 0.00647, t2-t1: 37.84338, trainL2: 0.02901, testL2: 0.00398\n",
            "epoch: 171, loss: 0.00649, t2-t1: 37.62172, trainL2: 0.02781, testL2: 0.00395\n",
            "epoch: 172, loss: 0.01039, t2-t1: 37.51110, trainL2: 0.03351, testL2: 0.00636\n",
            "epoch: 173, loss: 0.00754, t2-t1: 38.30241, trainL2: 0.03168, testL2: 0.00433\n",
            "epoch: 174, loss: 0.00752, t2-t1: 37.14020, trainL2: 0.02928, testL2: 0.00443\n",
            "epoch: 175, loss: 0.00699, t2-t1: 37.14998, trainL2: 0.02940, testL2: 0.00423\n",
            "epoch: 176, loss: 0.00651, t2-t1: 37.34639, trainL2: 0.02821, testL2: 0.00387\n",
            "epoch: 177, loss: 0.00703, t2-t1: 37.47113, trainL2: 0.02895, testL2: 0.00404\n",
            "epoch: 178, loss: 0.00756, t2-t1: 37.47558, trainL2: 0.02857, testL2: 0.00450\n",
            "epoch: 179, loss: 0.00786, t2-t1: 38.76890, trainL2: 0.03760, testL2: 0.00471\n",
            "epoch: 180, loss: 0.00633, t2-t1: 37.61547, trainL2: 0.02795, testL2: 0.00378\n",
            "epoch: 181, loss: 0.00658, t2-t1: 37.53868, trainL2: 0.02786, testL2: 0.00389\n",
            "epoch: 182, loss: 0.00672, t2-t1: 37.58606, trainL2: 0.02712, testL2: 0.00391\n",
            "epoch: 183, loss: 0.00834, t2-t1: 37.56148, trainL2: 0.02825, testL2: 0.00506\n",
            "epoch: 184, loss: 0.00641, t2-t1: 37.59728, trainL2: 0.04376, testL2: 0.00374\n",
            "epoch: 185, loss: 0.00641, t2-t1: 37.84679, trainL2: 0.02605, testL2: 0.00384\n",
            "epoch: 186, loss: 0.00682, t2-t1: 37.11060, trainL2: 0.02793, testL2: 0.00404\n",
            "epoch: 187, loss: 0.00657, t2-t1: 37.59350, trainL2: 0.02596, testL2: 0.00378\n",
            "epoch: 188, loss: 0.00659, t2-t1: 37.47296, trainL2: 0.02843, testL2: 0.00392\n",
            "epoch: 189, loss: 0.00797, t2-t1: 37.43655, trainL2: 0.03479, testL2: 0.00499\n",
            "epoch: 190, loss: 0.00702, t2-t1: 38.45191, trainL2: 0.02766, testL2: 0.00402\n",
            "epoch: 191, loss: 0.00653, t2-t1: 37.53286, trainL2: 0.02680, testL2: 0.00375\n",
            "epoch: 192, loss: 0.00744, t2-t1: 37.40646, trainL2: 0.02947, testL2: 0.00416\n",
            "epoch: 193, loss: 0.00732, t2-t1: 37.56744, trainL2: 0.03059, testL2: 0.00418\n",
            "epoch: 194, loss: 0.00725, t2-t1: 37.63869, trainL2: 0.02648, testL2: 0.00437\n",
            "epoch: 195, loss: 0.00634, t2-t1: 37.53077, trainL2: 0.02640, testL2: 0.00387\n",
            "epoch: 196, loss: 0.00690, t2-t1: 38.60030, trainL2: 0.03066, testL2: 0.00390\n",
            "epoch: 197, loss: 0.00695, t2-t1: 37.60643, trainL2: 0.02628, testL2: 0.00401\n",
            "epoch: 198, loss: 0.02073, t2-t1: 37.31768, trainL2: 0.02941, testL2: 0.01238\n",
            "epoch: 199, loss: 0.00617, t2-t1: 36.93893, trainL2: 0.03166, testL2: 0.00367\n",
            "epoch: 200, loss: 0.00578, t2-t1: 38.29446, trainL2: 0.02401, testL2: 0.00345\n",
            "epoch: 201, loss: 0.00585, t2-t1: 39.02421, trainL2: 0.02447, testL2: 0.00351\n",
            "epoch: 202, loss: 0.00580, t2-t1: 37.60525, trainL2: 0.02401, testL2: 0.00345\n",
            "epoch: 203, loss: 0.00605, t2-t1: 37.55841, trainL2: 0.02393, testL2: 0.00355\n",
            "epoch: 204, loss: 0.00580, t2-t1: 37.52191, trainL2: 0.02425, testL2: 0.00346\n",
            "epoch: 205, loss: 0.00594, t2-t1: 37.47478, trainL2: 0.02423, testL2: 0.00346\n",
            "epoch: 206, loss: 0.00598, t2-t1: 37.43203, trainL2: 0.02421, testL2: 0.00346\n",
            "epoch: 207, loss: 0.00591, t2-t1: 38.35080, trainL2: 0.02427, testL2: 0.00350\n",
            "epoch: 208, loss: 0.00618, t2-t1: 37.38967, trainL2: 0.02437, testL2: 0.00368\n",
            "epoch: 209, loss: 0.00618, t2-t1: 37.39123, trainL2: 0.02535, testL2: 0.00361\n",
            "epoch: 210, loss: 0.00587, t2-t1: 37.22208, trainL2: 0.02466, testL2: 0.00346\n",
            "epoch: 211, loss: 0.00594, t2-t1: 36.76981, trainL2: 0.02440, testL2: 0.00346\n",
            "epoch: 212, loss: 0.00600, t2-t1: 38.21906, trainL2: 0.02514, testL2: 0.00351\n",
            "epoch: 213, loss: 0.00650, t2-t1: 38.05027, trainL2: 0.02507, testL2: 0.00399\n",
            "epoch: 214, loss: 0.00602, t2-t1: 37.89336, trainL2: 0.02437, testL2: 0.00350\n",
            "epoch: 215, loss: 0.00589, t2-t1: 37.84041, trainL2: 0.02494, testL2: 0.00341\n",
            "epoch: 216, loss: 0.00577, t2-t1: 38.09773, trainL2: 0.02523, testL2: 0.00342\n",
            "epoch: 217, loss: 0.00623, t2-t1: 38.43520, trainL2: 0.02436, testL2: 0.00359\n",
            "epoch: 218, loss: 0.00604, t2-t1: 39.05407, trainL2: 0.02423, testL2: 0.00346\n",
            "epoch: 219, loss: 0.00728, t2-t1: 38.29986, trainL2: 0.02422, testL2: 0.00393\n",
            "epoch: 220, loss: 0.00767, t2-t1: 38.16527, trainL2: 0.02580, testL2: 0.00459\n",
            "epoch: 221, loss: 0.00586, t2-t1: 37.76205, trainL2: 0.02544, testL2: 0.00347\n",
            "epoch: 222, loss: 0.00572, t2-t1: 37.61613, trainL2: 0.02394, testL2: 0.00333\n",
            "epoch: 223, loss: 0.00595, t2-t1: 38.46105, trainL2: 0.02413, testL2: 0.00336\n",
            "epoch: 224, loss: 0.00582, t2-t1: 37.30607, trainL2: 0.02359, testL2: 0.00341\n",
            "epoch: 225, loss: 0.00582, t2-t1: 37.47078, trainL2: 0.02708, testL2: 0.00348\n",
            "epoch: 226, loss: 0.00562, t2-t1: 37.45849, trainL2: 0.02374, testL2: 0.00333\n",
            "epoch: 227, loss: 0.00581, t2-t1: 37.37083, trainL2: 0.02378, testL2: 0.00343\n",
            "epoch: 228, loss: 0.00621, t2-t1: 37.04185, trainL2: 0.02444, testL2: 0.00360\n",
            "epoch: 229, loss: 0.00571, t2-t1: 38.28654, trainL2: 0.02372, testL2: 0.00337\n",
            "epoch: 230, loss: 0.00586, t2-t1: 37.41584, trainL2: 0.02406, testL2: 0.00351\n",
            "epoch: 231, loss: 0.00578, t2-t1: 37.59756, trainL2: 0.02405, testL2: 0.00328\n",
            "epoch: 232, loss: 0.00571, t2-t1: 37.52644, trainL2: 0.02368, testL2: 0.00332\n",
            "epoch: 233, loss: 0.00582, t2-t1: 37.51612, trainL2: 0.02538, testL2: 0.00334\n",
            "epoch: 234, loss: 0.00704, t2-t1: 38.31421, trainL2: 0.02363, testL2: 0.00374\n",
            "epoch: 235, loss: 0.00624, t2-t1: 37.52906, trainL2: 0.02463, testL2: 0.00365\n",
            "epoch: 236, loss: 0.00578, t2-t1: 37.49624, trainL2: 0.02508, testL2: 0.00334\n",
            "epoch: 237, loss: 0.00580, t2-t1: 37.40060, trainL2: 0.02354, testL2: 0.00335\n",
            "epoch: 238, loss: 0.00565, t2-t1: 37.43664, trainL2: 0.02370, testL2: 0.00329\n",
            "epoch: 239, loss: 0.00579, t2-t1: 37.45403, trainL2: 0.02491, testL2: 0.00338\n",
            "epoch: 240, loss: 0.00612, t2-t1: 38.06665, trainL2: 0.02421, testL2: 0.00338\n",
            "epoch: 241, loss: 0.00559, t2-t1: 37.31227, trainL2: 0.02384, testL2: 0.00327\n",
            "epoch: 242, loss: 0.00574, t2-t1: 36.96026, trainL2: 0.02438, testL2: 0.00325\n",
            "epoch: 243, loss: 0.00559, t2-t1: 36.90401, trainL2: 0.02282, testL2: 0.00322\n",
            "epoch: 244, loss: 0.00558, t2-t1: 37.40170, trainL2: 0.02312, testL2: 0.00334\n",
            "epoch: 245, loss: 0.00616, t2-t1: 38.17137, trainL2: 0.02443, testL2: 0.00343\n",
            "epoch: 246, loss: 0.00603, t2-t1: 37.58037, trainL2: 0.02336, testL2: 0.00332\n",
            "epoch: 247, loss: 0.00588, t2-t1: 37.37342, trainL2: 0.02363, testL2: 0.00349\n",
            "epoch: 248, loss: 0.00604, t2-t1: 37.46848, trainL2: 0.02369, testL2: 0.00332\n",
            "epoch: 249, loss: 0.00558, t2-t1: 37.67231, trainL2: 0.02392, testL2: 0.00320\n",
            "epoch: 250, loss: 0.00599, t2-t1: 38.53971, trainL2: 0.02312, testL2: 0.00336\n",
            "epoch: 251, loss: 0.00567, t2-t1: 37.54251, trainL2: 0.02326, testL2: 0.00331\n",
            "epoch: 252, loss: 0.00539, t2-t1: 37.40470, trainL2: 0.02365, testL2: 0.00322\n",
            "epoch: 253, loss: 0.00547, t2-t1: 37.36789, trainL2: 0.02317, testL2: 0.00324\n",
            "epoch: 254, loss: 0.00561, t2-t1: 37.60090, trainL2: 0.02449, testL2: 0.00318\n",
            "epoch: 255, loss: 0.00647, t2-t1: 37.15865, trainL2: 0.02530, testL2: 0.00359\n",
            "epoch: 256, loss: 0.00554, t2-t1: 38.18050, trainL2: 0.02292, testL2: 0.00324\n",
            "epoch: 257, loss: 0.00593, t2-t1: 36.94547, trainL2: 0.02336, testL2: 0.00343\n",
            "epoch: 258, loss: 0.00560, t2-t1: 37.25213, trainL2: 0.02319, testL2: 0.00329\n",
            "epoch: 259, loss: 0.00560, t2-t1: 37.29515, trainL2: 0.02335, testL2: 0.00319\n",
            "epoch: 260, loss: 0.00546, t2-t1: 37.50089, trainL2: 0.02593, testL2: 0.00311\n",
            "epoch: 261, loss: 0.00544, t2-t1: 38.81046, trainL2: 0.02272, testL2: 0.00311\n",
            "epoch: 262, loss: 0.00579, t2-t1: 39.63098, trainL2: 0.02315, testL2: 0.00325\n",
            "epoch: 263, loss: 0.00561, t2-t1: 37.71772, trainL2: 0.02319, testL2: 0.00318\n",
            "epoch: 264, loss: 0.00622, t2-t1: 37.48034, trainL2: 0.02213, testL2: 0.00361\n",
            "epoch: 265, loss: 0.00531, t2-t1: 37.43474, trainL2: 0.02398, testL2: 0.00312\n",
            "epoch: 266, loss: 0.00561, t2-t1: 38.32101, trainL2: 0.02355, testL2: 0.00325\n",
            "epoch: 267, loss: 0.00549, t2-t1: 37.32539, trainL2: 0.02242, testL2: 0.00313\n",
            "epoch: 268, loss: 0.00562, t2-t1: 37.36528, trainL2: 0.02269, testL2: 0.00318\n",
            "epoch: 269, loss: 0.00524, t2-t1: 37.24577, trainL2: 0.02593, testL2: 0.00309\n",
            "epoch: 270, loss: 0.00596, t2-t1: 37.50508, trainL2: 0.02243, testL2: 0.00339\n",
            "epoch: 271, loss: 0.00690, t2-t1: 37.04771, trainL2: 0.02507, testL2: 0.00400\n",
            "epoch: 272, loss: 0.00545, t2-t1: 37.99866, trainL2: 0.02262, testL2: 0.00318\n",
            "epoch: 273, loss: 0.00554, t2-t1: 37.14833, trainL2: 0.02283, testL2: 0.00317\n",
            "epoch: 274, loss: 0.00602, t2-t1: 37.44109, trainL2: 0.02259, testL2: 0.00327\n",
            "epoch: 275, loss: 0.00586, t2-t1: 37.65028, trainL2: 0.02284, testL2: 0.00328\n",
            "epoch: 276, loss: 0.00605, t2-t1: 37.49650, trainL2: 0.02250, testL2: 0.00332\n",
            "epoch: 277, loss: 0.00533, t2-t1: 38.59334, trainL2: 0.02448, testL2: 0.00303\n",
            "epoch: 278, loss: 0.00575, t2-t1: 37.53785, trainL2: 0.02221, testL2: 0.00336\n",
            "epoch: 279, loss: 0.00527, t2-t1: 37.72774, trainL2: 0.02242, testL2: 0.00303\n",
            "epoch: 280, loss: 0.00534, t2-t1: 37.35314, trainL2: 0.02371, testL2: 0.00302\n",
            "epoch: 281, loss: 0.00548, t2-t1: 37.47249, trainL2: 0.02250, testL2: 0.00317\n",
            "epoch: 282, loss: 0.00535, t2-t1: 38.25637, trainL2: 0.02257, testL2: 0.00315\n",
            "epoch: 283, loss: 0.00619, t2-t1: 37.25050, trainL2: 0.02221, testL2: 0.00332\n",
            "epoch: 284, loss: 0.00526, t2-t1: 37.03261, trainL2: 0.02244, testL2: 0.00313\n",
            "epoch: 285, loss: 0.00564, t2-t1: 37.54574, trainL2: 0.02387, testL2: 0.00327\n",
            "epoch: 286, loss: 0.00580, t2-t1: 37.73236, trainL2: 0.02290, testL2: 0.00330\n",
            "epoch: 287, loss: 0.00535, t2-t1: 38.54079, trainL2: 0.02261, testL2: 0.00302\n",
            "epoch: 288, loss: 0.00578, t2-t1: 37.98788, trainL2: 0.02247, testL2: 0.00326\n",
            "epoch: 289, loss: 0.00573, t2-t1: 38.06576, trainL2: 0.02340, testL2: 0.00311\n",
            "epoch: 290, loss: 0.00538, t2-t1: 37.41285, trainL2: 0.02208, testL2: 0.00308\n",
            "epoch: 291, loss: 0.00624, t2-t1: 37.76565, trainL2: 0.02300, testL2: 0.00334\n",
            "epoch: 292, loss: 0.00536, t2-t1: 37.89618, trainL2: 0.02310, testL2: 0.00311\n",
            "epoch: 293, loss: 0.00571, t2-t1: 38.31361, trainL2: 0.02190, testL2: 0.00311\n",
            "epoch: 294, loss: 0.00552, t2-t1: 37.54872, trainL2: 0.02153, testL2: 0.00314\n",
            "epoch: 295, loss: 0.00550, t2-t1: 37.71678, trainL2: 0.02241, testL2: 0.00313\n",
            "epoch: 296, loss: 0.00671, t2-t1: 37.65059, trainL2: 0.02299, testL2: 0.00380\n",
            "epoch: 297, loss: 0.00541, t2-t1: 37.21928, trainL2: 0.02262, testL2: 0.00298\n",
            "epoch: 298, loss: 0.00586, t2-t1: 38.44393, trainL2: 0.02320, testL2: 0.00332\n",
            "epoch: 299, loss: 0.00559, t2-t1: 37.34043, trainL2: 0.02281, testL2: 0.00330\n",
            "epoch: 300, loss: 0.00505, t2-t1: 37.21926, trainL2: 0.02055, testL2: 0.00287\n",
            "epoch: 301, loss: 0.00493, t2-t1: 37.16970, trainL2: 0.02041, testL2: 0.00283\n",
            "epoch: 302, loss: 0.00502, t2-t1: 38.14456, trainL2: 0.02033, testL2: 0.00283\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Be1TnA0x0P7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CpEWWy380P4t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}