{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bdwmm9U8UQhL"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "from timeit import default_timer\n",
        "\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "import logging\n",
        "import h5py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "X-Ct6GqnmEmQ"
      },
      "outputs": [],
      "source": [
        "class GatingTransformer(nn.Module):\n",
        "    \"\"\"\n",
        "    Transforms the original input to match target resolution and channels\n",
        "    for use in the gating mechanism at different layers\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, target_size):\n",
        "        super(GatingTransformer, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.target_size = target_size\n",
        "\n",
        "        # Transform input channels to match layer's channel requirement\n",
        "        self.channel_transform = nn.Conv1d(\n",
        "            in_channels=in_channels,\n",
        "            out_channels=out_channels,\n",
        "            kernel_size=1\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Resize input to target resolution\n",
        "        x = F.interpolate(x, size=self.target_size, mode='linear', align_corners=False)\n",
        "        # Transform channels\n",
        "        x = self.channel_transform(x)\n",
        "        return x\n",
        "\n",
        "class DLGN_Gate(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements the gating mechanism for DLGN\n",
        "    G_l(x) = σ(βU_l^T x)\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, target_size, beta=1.0):\n",
        "        super(DLGN_Gate, self).__init__()\n",
        "        self.beta = beta\n",
        "        self.target_size = target_size\n",
        "        self.transformer = GatingTransformer(in_channels, out_channels, target_size)\n",
        "        self.gate_weights = nn.Conv1d(\n",
        "            in_channels=out_channels,\n",
        "            out_channels=out_channels,\n",
        "            kernel_size=3,\n",
        "            padding=1\n",
        "        )\n",
        "\n",
        "    def forward(self, original_input):\n",
        "        # Transform original input to match current layer dimensions\n",
        "        x = self.transformer(original_input)\n",
        "        # Apply gating weights (U_l^T x)\n",
        "        x = self.gate_weights(x)\n",
        "        # Apply sigmoid activation with beta parameter\n",
        "        return torch.sigmoid(self.beta * x)\n",
        "\n",
        "class DLGN_Layer(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements the DLGN activation mechanism\n",
        "    ψ^(l)(x) = G_l(x) ⊙ (W_l^T ψ^(l-1)(x))\n",
        "    \"\"\"\n",
        "    def __init__(self, in_size, out_size):\n",
        "        super(DLGN_Layer, self).__init__()\n",
        "        self.in_size = in_size\n",
        "        self.out_size = out_size\n",
        "\n",
        "    def forward(self, x, gate):\n",
        "        # Resize input to desired output size (double size first as in original CNO_LReLu)\n",
        "        x = F.interpolate(x.unsqueeze(2), size=(1, 2 * self.in_size), mode=\"bicubic\", antialias=True)\n",
        "\n",
        "        # Make sure gate has the right shape for broadcasting\n",
        "        if gate.shape != x.shape:\n",
        "            # Reshape gate to match the interpolated x\n",
        "            gate = gate.unsqueeze(2) if gate.dim() == 3 else gate\n",
        "            gate = F.interpolate(gate, size=x.size()[2:], mode=\"nearest\")\n",
        "\n",
        "        # Element-wise multiplication with gate\n",
        "        x = gate * x\n",
        "\n",
        "        # Resize to final output size\n",
        "        x = F.interpolate(x, size=(1, self.out_size), mode=\"bicubic\", antialias=True)\n",
        "        return x[:,:,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2OKSfpwpUSEv"
      },
      "outputs": [],
      "source": [
        "class CNOBlock_DLGN(nn.Module):\n",
        "    \"\"\"\n",
        "    Modified CNOBlock to use DLGN instead of traditional activation\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 in_channels,\n",
        "                 out_channels,\n",
        "                 in_size,\n",
        "                 out_size,\n",
        "                 original_channels,\n",
        "                 beta=1.0,\n",
        "                 use_bn=True):\n",
        "        super(CNOBlock_DLGN, self).__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.in_size = in_size\n",
        "        self.out_size = out_size\n",
        "\n",
        "        # Convolution layer\n",
        "        self.convolution = torch.nn.Conv1d(in_channels=self.in_channels,\n",
        "                                          out_channels=self.out_channels,\n",
        "                                          kernel_size=3,\n",
        "                                          padding=1)\n",
        "\n",
        "        # Batch normalization (optional)\n",
        "        if use_bn:\n",
        "            self.batch_norm = nn.BatchNorm1d(self.out_channels)\n",
        "        else:\n",
        "            self.batch_norm = nn.Identity()\n",
        "\n",
        "        # DLGN components\n",
        "        self.gating = DLGN_Gate(original_channels, out_channels, out_size, beta)\n",
        "        self.dlgn_layer = DLGN_Layer(in_size=self.in_size, out_size=self.out_size)\n",
        "\n",
        "    def forward(self, x, original_input):\n",
        "        # Apply convolution and batch norm\n",
        "        x = self.convolution(x)\n",
        "        x = self.batch_norm(x)\n",
        "\n",
        "        # Get gating signal from original input\n",
        "        gate = self.gating(original_input)\n",
        "\n",
        "        # Apply DLGN layer\n",
        "        return self.dlgn_layer(x, gate)\n",
        "\n",
        "class LiftProjectBlock_DLGN(nn.Module):\n",
        "    \"\"\"\n",
        "    Modified LiftProjectBlock to use DLGN\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                in_channels,\n",
        "                out_channels,\n",
        "                size,\n",
        "                original_channels,\n",
        "                beta=1.0,\n",
        "                latent_dim=64):\n",
        "        super(LiftProjectBlock_DLGN, self).__init__()\n",
        "\n",
        "        self.inter_CNOBlock = CNOBlock_DLGN(in_channels=in_channels,\n",
        "                                           out_channels=latent_dim,\n",
        "                                           in_size=size,\n",
        "                                           out_size=size,\n",
        "                                           original_channels=original_channels,\n",
        "                                           beta=beta,\n",
        "                                           use_bn=False)\n",
        "\n",
        "        self.convolution = torch.nn.Conv1d(in_channels=latent_dim,\n",
        "                                          out_channels=out_channels,\n",
        "                                          kernel_size=3,\n",
        "                                          padding=1)\n",
        "\n",
        "    def forward(self, x, original_input):\n",
        "        x = self.inter_CNOBlock(x, original_input)\n",
        "        x = self.convolution(x)\n",
        "        return x\n",
        "\n",
        "class ResidualBlock_DLGN(nn.Module):\n",
        "    \"\"\"\n",
        "    Modified ResidualBlock to use DLGN\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 channels,\n",
        "                 size,\n",
        "                 original_channels,\n",
        "                 beta=1.0,\n",
        "                 use_bn=True):\n",
        "        super(ResidualBlock_DLGN, self).__init__()\n",
        "\n",
        "        self.channels = channels\n",
        "        self.size = size\n",
        "\n",
        "        # First convolution path\n",
        "        self.convolution1 = torch.nn.Conv1d(in_channels=self.channels,\n",
        "                                           out_channels=self.channels,\n",
        "                                           kernel_size=3,\n",
        "                                           padding=1)\n",
        "\n",
        "        # Second convolution path\n",
        "        self.convolution2 = torch.nn.Conv1d(in_channels=self.channels,\n",
        "                                           out_channels=self.channels,\n",
        "                                           kernel_size=3,\n",
        "                                           padding=1)\n",
        "\n",
        "        # Batch normalization (optional)\n",
        "        if use_bn:\n",
        "            self.batch_norm1 = nn.BatchNorm1d(self.channels)\n",
        "            self.batch_norm2 = nn.BatchNorm1d(self.channels)\n",
        "        else:\n",
        "            self.batch_norm1 = nn.Identity()\n",
        "            self.batch_norm2 = nn.Identity()\n",
        "\n",
        "        # DLGN components\n",
        "        self.gating1 = DLGN_Gate(original_channels, channels, size, beta)\n",
        "        self.gating2 = DLGN_Gate(original_channels, channels, size, beta)\n",
        "        self.dlgn_layer1 = DLGN_Layer(in_size=self.size, out_size=self.size)\n",
        "        self.dlgn_layer2 = DLGN_Layer(in_size=self.size, out_size=self.size)\n",
        "\n",
        "    def forward(self, x, original_input):\n",
        "        identity = x\n",
        "\n",
        "        # First convolution path\n",
        "        out = self.convolution1(x)\n",
        "        out = self.batch_norm1(out)\n",
        "\n",
        "        # Apply first DLGN layer\n",
        "        gate1 = self.gating1(original_input)\n",
        "        out = self.dlgn_layer1(out, gate1)\n",
        "\n",
        "        # Second convolution path\n",
        "        out = self.convolution2(out)\n",
        "        out = self.batch_norm2(out)\n",
        "\n",
        "        # Apply second DLGN layer\n",
        "        gate2 = self.gating2(original_input)\n",
        "        out = self.dlgn_layer2(out, gate2)\n",
        "\n",
        "        # Apply residual connection\n",
        "        return identity + out\n",
        "\n",
        "class ResNet_DLGN(nn.Module):\n",
        "    \"\"\"\n",
        "    Modified ResNet to use DLGN\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 channels,\n",
        "                 size,\n",
        "                 original_channels,\n",
        "                 num_blocks,\n",
        "                 beta=1.0,\n",
        "                 use_bn=True):\n",
        "        super(ResNet_DLGN, self).__init__()\n",
        "\n",
        "        self.channels = channels\n",
        "        self.size = size\n",
        "        self.num_blocks = num_blocks\n",
        "        self.original_channels = original_channels\n",
        "\n",
        "        # Create resnet blocks\n",
        "        self.res_blocks = nn.ModuleList([\n",
        "            ResidualBlock_DLGN(\n",
        "                channels=channels,\n",
        "                size=size,\n",
        "                original_channels=original_channels,\n",
        "                beta=beta,\n",
        "                use_bn=use_bn\n",
        "            ) for _ in range(num_blocks)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x, original_input):\n",
        "        for block in self.res_blocks:\n",
        "            x = block(x, original_input)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rqgpkOw4USCE"
      },
      "outputs": [],
      "source": [
        "class CNO1d(nn.Module):\n",
        "    def __init__(self,\n",
        "                 num_channels,           # Number of input/output channels\n",
        "                 width=64,               # Base width for the network\n",
        "                 initial_step=10,        # Number of initial timesteps\n",
        "                 size=None,              # Spatial size of the domain\n",
        "                 N_layers=4,             # Number of (D) or (U) blocks in the network\n",
        "                 N_res=4,                # Number of (R) blocks per level (except the neck)\n",
        "                 N_res_neck=4,           # Number of (R) blocks in the neck\n",
        "                 channel_multiplier=16,  # How the number of channels evolve\n",
        "                 use_bn=True             # Add BN? We do not add BN in lifting/projection layer\n",
        "                ):\n",
        "        super(CNO1d, self).__init__()\n",
        "\n",
        "        # Store parameters\n",
        "        self.num_channels = num_channels\n",
        "        self.initial_step = initial_step\n",
        "        self.width = width\n",
        "\n",
        "        # Determine spatial size if not provided\n",
        "        if size is None:\n",
        "            size = 128  # Default spatial size\n",
        "\n",
        "        # Create the CNO1d architecture\n",
        "        self.model = CNO1d_DLGN(\n",
        "            in_dim=initial_step * num_channels + 1,  # Input: initial_step channels + grid\n",
        "            out_dim=num_channels,                    # Output: predict next channel values\n",
        "            size=size,\n",
        "            N_layers=N_layers,\n",
        "            N_res=N_res,\n",
        "            N_res_neck=N_res_neck,\n",
        "            channel_multiplier=channel_multiplier,\n",
        "            use_bn=use_bn\n",
        "        )\n",
        "\n",
        "    def forward(self, x, grid):\n",
        "        # x dim = [b, x1, t*v] - same input format as FNO1d\n",
        "        # Combine x and grid to match CNO1d_Core input format\n",
        "        inputs = torch.cat((x, grid), dim=-1)  # concatenate along feature dimension\n",
        "\n",
        "        # Reshape for CNO: [batch, channels, spatial_dim]\n",
        "        batch_size = inputs.shape[0]\n",
        "        spatial_dim = inputs.shape[1]\n",
        "        inputs = inputs.permute(0, 2, 1)  # [batch, features, spatial]\n",
        "\n",
        "        # Forward pass through CNO\n",
        "        out = self.model(inputs)\n",
        "\n",
        "        # Reshape back to expected output format: [batch, spatial, channels, 1]\n",
        "        out = out.permute(0, 2, 1)  # [batch, spatial, channels]\n",
        "        out = out.unsqueeze(-2)     # [batch, spatial, 1, channels]\n",
        "\n",
        "        return out\n",
        "\n",
        "class CNO1d_DLGN(nn.Module):\n",
        "    \"\"\"\n",
        "    Modified CNO1d to use DLGN framework\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 in_dim,                    # Number of input channels\n",
        "                 out_dim,                   # Number of output channels\n",
        "                 size,                      # Input and Output spatial size\n",
        "                 N_layers,                  # Number of (D) or (U) blocks\n",
        "                 N_res=4,                   # Number of (R) blocks per level\n",
        "                 N_res_neck=4,              # Number of (R) blocks in the neck\n",
        "                 channel_multiplier=16,     # Channel evolution factor\n",
        "                 beta=1.0,                  # Beta parameter for DLGN\n",
        "                 use_bn=True,               # Use batch normalization\n",
        "                ):\n",
        "        super(CNO1d_DLGN, self).__init__()\n",
        "\n",
        "        self.N_layers = int(N_layers)\n",
        "        self.lift_dim = channel_multiplier//2\n",
        "        self.in_dim = in_dim\n",
        "        self.out_dim = out_dim\n",
        "        self.channel_multiplier = channel_multiplier\n",
        "        self.beta = beta\n",
        "\n",
        "        ######## Num of channels/features - evolution ########\n",
        "        self.encoder_features = [self.lift_dim]\n",
        "        for i in range(self.N_layers):\n",
        "            self.encoder_features.append(2 ** i * self.channel_multiplier)\n",
        "\n",
        "        self.decoder_features_in = self.encoder_features[1:]\n",
        "        self.decoder_features_in.reverse()\n",
        "        self.decoder_features_out = self.encoder_features[:-1]\n",
        "        self.decoder_features_out.reverse()\n",
        "\n",
        "        for i in range(1, self.N_layers):\n",
        "            self.decoder_features_in[i] = 2 * self.decoder_features_in[i]\n",
        "\n",
        "        ######## Spatial sizes of channels - evolution ########\n",
        "        self.encoder_sizes = []\n",
        "        self.decoder_sizes = []\n",
        "        for i in range(self.N_layers + 1):\n",
        "            self.encoder_sizes.append(size // 2 ** i)\n",
        "            self.decoder_sizes.append(size // 2 ** (self.N_layers - i))\n",
        "\n",
        "        ######## Define Lift and Project blocks ########\n",
        "        self.lift = LiftProjectBlock_DLGN(\n",
        "            in_channels=in_dim,\n",
        "            out_channels=self.encoder_features[0],\n",
        "            size=size,\n",
        "            original_channels=in_dim,\n",
        "            beta=beta\n",
        "        )\n",
        "\n",
        "        self.project = LiftProjectBlock_DLGN(\n",
        "            in_channels=self.encoder_features[0] + self.decoder_features_out[-1],\n",
        "            out_channels=out_dim,\n",
        "            size=size,\n",
        "            original_channels=in_dim,\n",
        "            beta=beta\n",
        "        )\n",
        "\n",
        "        ######## Define Encoder, ED Linker and Decoder networks ########\n",
        "        self.encoder = nn.ModuleList([\n",
        "            CNOBlock_DLGN(\n",
        "                in_channels=self.encoder_features[i],\n",
        "                out_channels=self.encoder_features[i+1],\n",
        "                in_size=self.encoder_sizes[i],\n",
        "                out_size=self.encoder_sizes[i+1],\n",
        "                original_channels=in_dim,\n",
        "                beta=beta,\n",
        "                use_bn=use_bn\n",
        "            ) for i in range(self.N_layers)\n",
        "        ])\n",
        "\n",
        "        # ED expansion blocks\n",
        "        self.ED_expansion = nn.ModuleList([\n",
        "            CNOBlock_DLGN(\n",
        "                in_channels=self.encoder_features[i],\n",
        "                out_channels=self.encoder_features[i],\n",
        "                in_size=self.encoder_sizes[i],\n",
        "                out_size=self.decoder_sizes[self.N_layers - i],\n",
        "                original_channels=in_dim,\n",
        "                beta=beta,\n",
        "                use_bn=use_bn\n",
        "            ) for i in range(self.N_layers + 1)\n",
        "        ])\n",
        "\n",
        "        # Decoder blocks\n",
        "        self.decoder = nn.ModuleList([\n",
        "            CNOBlock_DLGN(\n",
        "                in_channels=self.decoder_features_in[i],\n",
        "                out_channels=self.decoder_features_out[i],\n",
        "                in_size=self.decoder_sizes[i],\n",
        "                out_size=self.decoder_sizes[i+1],\n",
        "                original_channels=in_dim,\n",
        "                beta=beta,\n",
        "                use_bn=use_bn\n",
        "            ) for i in range(self.N_layers)\n",
        "        ])\n",
        "\n",
        "        ######## Define ResNets Blocks ########\n",
        "        self.res_nets = nn.ModuleList([\n",
        "            ResNet_DLGN(\n",
        "                channels=self.encoder_features[l],\n",
        "                size=self.encoder_sizes[l],\n",
        "                original_channels=in_dim,\n",
        "                num_blocks=N_res,\n",
        "                beta=beta,\n",
        "                use_bn=use_bn\n",
        "            ) for l in range(self.N_layers)\n",
        "        ])\n",
        "\n",
        "        # Bottleneck ResNet\n",
        "        self.res_net_neck = ResNet_DLGN(\n",
        "            channels=self.encoder_features[self.N_layers],\n",
        "            size=self.encoder_sizes[self.N_layers],\n",
        "            original_channels=in_dim,\n",
        "            num_blocks=N_res_neck,\n",
        "            beta=beta,\n",
        "            use_bn=use_bn\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Store original input for gating\n",
        "        original_input = x.clone()\n",
        "\n",
        "        # Execute lift\n",
        "        x = self.lift(x, original_input)\n",
        "        skip = []\n",
        "\n",
        "        # Execute encoder\n",
        "        for i in range(self.N_layers):\n",
        "            # Apply ResNet & save result\n",
        "            y = self.res_nets[i](x, original_input)\n",
        "            skip.append(y)\n",
        "\n",
        "            # Apply (D) block\n",
        "            x = self.encoder[i](x, original_input)\n",
        "\n",
        "        # Apply bottleneck ResNet\n",
        "        x = self.res_net_neck(x, original_input)\n",
        "\n",
        "        # Execute decoder\n",
        "        for i in range(self.N_layers):\n",
        "            # Apply (I) block (ED_expansion) & cat if needed\n",
        "            if i == 0:\n",
        "                x = self.ED_expansion[self.N_layers - i](x, original_input)  # Bottleneck: no cat\n",
        "            else:\n",
        "                exp_skip = self.ED_expansion[self.N_layers - i](skip[-i], original_input)\n",
        "                x = torch.cat((x, exp_skip), 1)\n",
        "\n",
        "            # Apply (U) block\n",
        "            x = self.decoder[i](x, original_input)\n",
        "\n",
        "        # Cat & execute projection\n",
        "        exp_skip = self.ED_expansion[0](skip[0], original_input)\n",
        "        x = torch.cat((x, exp_skip), 1)\n",
        "        x = self.project(x, original_input)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5WRmCUIwVnMM"
      },
      "outputs": [],
      "source": [
        "class FNODatasetSingle(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        filename,\n",
        "        initial_step=10,\n",
        "        saved_folder=\"../data/\",\n",
        "        reduced_resolution=1,\n",
        "        reduced_resolution_t=1,\n",
        "        reduced_batch=1,\n",
        "        if_test=False,\n",
        "        test_ratio=0.1,\n",
        "        num_samples_max=-1,\n",
        "    ):\n",
        "        \"\"\"\n",
        "\n",
        "        :param filename: filename that contains the dataset\n",
        "        :type filename: STR\n",
        "        :param filenum: array containing indices of filename included in the dataset\n",
        "        :type filenum: ARRAY\n",
        "        :param initial_step: time steps taken as initial condition, defaults to 10\n",
        "        :type initial_step: INT, optional\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        # Define path to files\n",
        "        root_path = Path(Path(saved_folder).resolve()) / filename\n",
        "        if filename[-2:] != \"h5\":\n",
        "            # print(\".HDF5 file extension is assumed hereafter\")\n",
        "\n",
        "            with h5py.File(root_path, \"r\") as f:\n",
        "                keys = list(f.keys())\n",
        "                keys.sort()\n",
        "                if \"tensor\" not in keys:\n",
        "                    _data = np.array(\n",
        "                        f[\"density\"], dtype=np.float32\n",
        "                    )  # batch, time, x,...\n",
        "                    idx_cfd = _data.shape\n",
        "                    if len(idx_cfd) == 3:  # 1D\n",
        "                        self.data = np.zeros(\n",
        "                            [\n",
        "                                idx_cfd[0] // reduced_batch,\n",
        "                                idx_cfd[2] // reduced_resolution,\n",
        "                                mt.ceil(idx_cfd[1] / reduced_resolution_t),\n",
        "                                3,\n",
        "                            ],\n",
        "                            dtype=np.float32,\n",
        "                        )\n",
        "                        # density\n",
        "                        _data = _data[\n",
        "                            ::reduced_batch,\n",
        "                            ::reduced_resolution_t,\n",
        "                            ::reduced_resolution,\n",
        "                        ]\n",
        "                        ## convert to [x1, ..., xd, t, v]\n",
        "                        _data = np.transpose(_data[:, :, :], (0, 2, 1))\n",
        "                        self.data[..., 0] = _data  # batch, x, t, ch\n",
        "                        # pressure\n",
        "                        _data = np.array(\n",
        "                            f[\"pressure\"], dtype=np.float32\n",
        "                        )  # batch, time, x,...\n",
        "                        _data = _data[\n",
        "                            ::reduced_batch,\n",
        "                            ::reduced_resolution_t,\n",
        "                            ::reduced_resolution,\n",
        "                        ]\n",
        "                        ## convert to [x1, ..., xd, t, v]\n",
        "                        _data = np.transpose(_data[:, :, :], (0, 2, 1))\n",
        "                        self.data[..., 1] = _data  # batch, x, t, ch\n",
        "                        # Vx\n",
        "                        _data = np.array(\n",
        "                            f[\"Vx\"], dtype=np.float32\n",
        "                        )  # batch, time, x,...\n",
        "                        _data = _data[\n",
        "                            ::reduced_batch,\n",
        "                            ::reduced_resolution_t,\n",
        "                            ::reduced_resolution,\n",
        "                        ]\n",
        "                        ## convert to [x1, ..., xd, t, v]\n",
        "                        _data = np.transpose(_data[:, :, :], (0, 2, 1))\n",
        "                        self.data[..., 2] = _data  # batch, x, t, ch\n",
        "\n",
        "                        self.grid = np.array(f[\"x-coordinate\"], dtype=np.float32)\n",
        "                        self.grid = torch.tensor(\n",
        "                            self.grid[::reduced_resolution], dtype=torch.float\n",
        "                        ).unsqueeze(-1)\n",
        "                        # print(self.data.shape)\n",
        "                    if len(idx_cfd) == 4:  # 2D\n",
        "                        self.data = np.zeros(\n",
        "                            [\n",
        "                                idx_cfd[0] // reduced_batch,\n",
        "                                idx_cfd[2] // reduced_resolution,\n",
        "                                idx_cfd[3] // reduced_resolution,\n",
        "                                mt.ceil(idx_cfd[1] / reduced_resolution_t),\n",
        "                                4,\n",
        "                            ],\n",
        "                            dtype=np.float32,\n",
        "                        )\n",
        "                        # density\n",
        "                        _data = _data[\n",
        "                            ::reduced_batch,\n",
        "                            ::reduced_resolution_t,\n",
        "                            ::reduced_resolution,\n",
        "                            ::reduced_resolution,\n",
        "                        ]\n",
        "                        ## convert to [x1, ..., xd, t, v]\n",
        "                        _data = np.transpose(_data, (0, 2, 3, 1))\n",
        "                        self.data[..., 0] = _data  # batch, x, t, ch\n",
        "                        # pressure\n",
        "                        _data = np.array(\n",
        "                            f[\"pressure\"], dtype=np.float32\n",
        "                        )  # batch, time, x,...\n",
        "                        _data = _data[\n",
        "                            ::reduced_batch,\n",
        "                            ::reduced_resolution_t,\n",
        "                            ::reduced_resolution,\n",
        "                            ::reduced_resolution,\n",
        "                        ]\n",
        "                        ## convert to [x1, ..., xd, t, v]\n",
        "                        _data = np.transpose(_data, (0, 2, 3, 1))\n",
        "                        self.data[..., 1] = _data  # batch, x, t, ch\n",
        "                        # Vx\n",
        "                        _data = np.array(\n",
        "                            f[\"Vx\"], dtype=np.float32\n",
        "                        )  # batch, time, x,...\n",
        "                        _data = _data[\n",
        "                            ::reduced_batch,\n",
        "                            ::reduced_resolution_t,\n",
        "                            ::reduced_resolution,\n",
        "                            ::reduced_resolution,\n",
        "                        ]\n",
        "                        ## convert to [x1, ..., xd, t, v]\n",
        "                        _data = np.transpose(_data, (0, 2, 3, 1))\n",
        "                        self.data[..., 2] = _data  # batch, x, t, ch\n",
        "                        # Vy\n",
        "                        _data = np.array(\n",
        "                            f[\"Vy\"], dtype=np.float32\n",
        "                        )  # batch, time, x,...\n",
        "                        _data = _data[\n",
        "                            ::reduced_batch,\n",
        "                            ::reduced_resolution_t,\n",
        "                            ::reduced_resolution,\n",
        "                            ::reduced_resolution,\n",
        "                        ]\n",
        "                        ## convert to [x1, ..., xd, t, v]\n",
        "                        _data = np.transpose(_data, (0, 2, 3, 1))\n",
        "                        self.data[..., 3] = _data  # batch, x, t, ch\n",
        "\n",
        "                        x = np.array(f[\"x-coordinate\"], dtype=np.float32)\n",
        "                        y = np.array(f[\"y-coordinate\"], dtype=np.float32)\n",
        "                        x = torch.tensor(x, dtype=torch.float)\n",
        "                        y = torch.tensor(y, dtype=torch.float)\n",
        "                        X, Y = torch.meshgrid(x, y, indexing=\"ij\")\n",
        "                        self.grid = torch.stack((X, Y), axis=-1)[\n",
        "                            ::reduced_resolution, ::reduced_resolution\n",
        "                        ]\n",
        "\n",
        "                    if len(idx_cfd) == 5:  # 3D\n",
        "                        self.data = np.zeros(\n",
        "                            [\n",
        "                                idx_cfd[0] // reduced_batch,\n",
        "                                idx_cfd[2] // reduced_resolution,\n",
        "                                idx_cfd[3] // reduced_resolution,\n",
        "                                idx_cfd[4] // reduced_resolution,\n",
        "                                mt.ceil(idx_cfd[1] / reduced_resolution_t),\n",
        "                                5,\n",
        "                            ],\n",
        "                            dtype=np.float32,\n",
        "                        )\n",
        "                        # density\n",
        "                        _data = _data[\n",
        "                            ::reduced_batch,\n",
        "                            ::reduced_resolution_t,\n",
        "                            ::reduced_resolution,\n",
        "                            ::reduced_resolution,\n",
        "                            ::reduced_resolution,\n",
        "                        ]\n",
        "                        ## convert to [x1, ..., xd, t, v]\n",
        "                        _data = np.transpose(_data, (0, 2, 3, 4, 1))\n",
        "                        self.data[..., 0] = _data  # batch, x, t, ch\n",
        "                        # pressure\n",
        "                        _data = np.array(\n",
        "                            f[\"pressure\"], dtype=np.float32\n",
        "                        )  # batch, time, x,...\n",
        "                        _data = _data[\n",
        "                            ::reduced_batch,\n",
        "                            ::reduced_resolution_t,\n",
        "                            ::reduced_resolution,\n",
        "                            ::reduced_resolution,\n",
        "                            ::reduced_resolution,\n",
        "                        ]\n",
        "                        ## convert to [x1, ..., xd, t, v]\n",
        "                        _data = np.transpose(_data, (0, 2, 3, 4, 1))\n",
        "                        self.data[..., 1] = _data  # batch, x, t, ch\n",
        "                        # Vx\n",
        "                        _data = np.array(\n",
        "                            f[\"Vx\"], dtype=np.float32\n",
        "                        )  # batch, time, x,...\n",
        "                        _data = _data[\n",
        "                            ::reduced_batch,\n",
        "                            ::reduced_resolution_t,\n",
        "                            ::reduced_resolution,\n",
        "                            ::reduced_resolution,\n",
        "                            ::reduced_resolution,\n",
        "                        ]\n",
        "                        ## convert to [x1, ..., xd, t, v]\n",
        "                        _data = np.transpose(_data, (0, 2, 3, 4, 1))\n",
        "                        self.data[..., 2] = _data  # batch, x, t, ch\n",
        "                        # Vy\n",
        "                        _data = np.array(\n",
        "                            f[\"Vy\"], dtype=np.float32\n",
        "                        )  # batch, time, x,...\n",
        "                        _data = _data[\n",
        "                            ::reduced_batch,\n",
        "                            ::reduced_resolution_t,\n",
        "                            ::reduced_resolution,\n",
        "                            ::reduced_resolution,\n",
        "                            ::reduced_resolution,\n",
        "                        ]\n",
        "                        ## convert to [x1, ..., xd, t, v]\n",
        "                        _data = np.transpose(_data, (0, 2, 3, 4, 1))\n",
        "                        self.data[..., 3] = _data  # batch, x, t, ch\n",
        "                        # Vz\n",
        "                        _data = np.array(\n",
        "                            f[\"Vz\"], dtype=np.float32\n",
        "                        )  # batch, time, x,...\n",
        "                        _data = _data[\n",
        "                            ::reduced_batch,\n",
        "                            ::reduced_resolution_t,\n",
        "                            ::reduced_resolution,\n",
        "                            ::reduced_resolution,\n",
        "                            ::reduced_resolution,\n",
        "                        ]\n",
        "                        ## convert to [x1, ..., xd, t, v]\n",
        "                        _data = np.transpose(_data, (0, 2, 3, 4, 1))\n",
        "                        self.data[..., 4] = _data  # batch, x, t, ch\n",
        "\n",
        "                        x = np.array(f[\"x-coordinate\"], dtype=np.float32)\n",
        "                        y = np.array(f[\"y-coordinate\"], dtype=np.float32)\n",
        "                        z = np.array(f[\"z-coordinate\"], dtype=np.float32)\n",
        "                        x = torch.tensor(x, dtype=torch.float)\n",
        "                        y = torch.tensor(y, dtype=torch.float)\n",
        "                        z = torch.tensor(z, dtype=torch.float)\n",
        "                        X, Y, Z = torch.meshgrid(x, y, z, indexing=\"ij\")\n",
        "                        self.grid = torch.stack((X, Y, Z), axis=-1)[\n",
        "                            ::reduced_resolution,\n",
        "                            ::reduced_resolution,\n",
        "                            ::reduced_resolution,\n",
        "                        ]\n",
        "\n",
        "                else:  # scalar equations\n",
        "                    ## data dim = [t, x1, ..., xd, v]\n",
        "                    _data = np.array(\n",
        "                        f[\"tensor\"], dtype=np.float32\n",
        "                    )  # batch, time, x,...\n",
        "                    if len(_data.shape) == 3:  # 1D\n",
        "                        _data = _data[\n",
        "                            ::reduced_batch,\n",
        "                            ::reduced_resolution_t,\n",
        "                            ::reduced_resolution,\n",
        "                        ]\n",
        "                        ## convert to [x1, ..., xd, t, v]\n",
        "                        _data = np.transpose(_data[:, :, :], (0, 2, 1))\n",
        "                        self.data = _data[:, :, :, None]  # batch, x, t, ch\n",
        "\n",
        "                        self.grid = np.array(f[\"x-coordinate\"], dtype=np.float32)\n",
        "                        self.grid = torch.tensor(\n",
        "                            self.grid[::reduced_resolution], dtype=torch.float\n",
        "                        ).unsqueeze(-1)\n",
        "                    if len(_data.shape) == 4:  # 2D Darcy flow\n",
        "                        # u: label\n",
        "                        _data = _data[\n",
        "                            ::reduced_batch,\n",
        "                            :,\n",
        "                            ::reduced_resolution,\n",
        "                            ::reduced_resolution,\n",
        "                        ]\n",
        "                        ## convert to [x1, ..., xd, t, v]\n",
        "                        _data = np.transpose(_data[:, :, :, :], (0, 2, 3, 1))\n",
        "                        # if _data.shape[-1]==1:  # if nt==1\n",
        "                        #    _data = np.tile(_data, (1, 1, 1, 2))\n",
        "                        self.data = _data\n",
        "                        # nu: input\n",
        "                        _data = np.array(\n",
        "                            f[\"nu\"], dtype=np.float32\n",
        "                        )  # batch, time, x,...\n",
        "                        _data = _data[\n",
        "                            ::reduced_batch,\n",
        "                            None,\n",
        "                            ::reduced_resolution,\n",
        "                            ::reduced_resolution,\n",
        "                        ]\n",
        "                        ## convert to [x1, ..., xd, t, v]\n",
        "                        _data = np.transpose(_data[:, :, :, :], (0, 2, 3, 1))\n",
        "                        self.data = np.concatenate([_data, self.data], axis=-1)\n",
        "                        self.data = self.data[:, :, :, :, None]  # batch, x, y, t, ch\n",
        "\n",
        "                        x = np.array(f[\"x-coordinate\"], dtype=np.float32)\n",
        "                        y = np.array(f[\"y-coordinate\"], dtype=np.float32)\n",
        "                        x = torch.tensor(x, dtype=torch.float)\n",
        "                        y = torch.tensor(y, dtype=torch.float)\n",
        "                        X, Y = torch.meshgrid(x, y, indexing=\"ij\")\n",
        "                        self.grid = torch.stack((X, Y), axis=-1)[\n",
        "                            ::reduced_resolution, ::reduced_resolution\n",
        "                        ]\n",
        "\n",
        "        elif filename[-2:] == \"h5\":  # SWE-2D (RDB)\n",
        "            # print(\".H5 file extension is assumed hereafter\")\n",
        "\n",
        "            with h5py.File(root_path, \"r\") as f:\n",
        "                keys = list(f.keys())\n",
        "                keys.sort()\n",
        "\n",
        "                data_arrays = [\n",
        "                    np.array(f[key][\"data\"], dtype=np.float32) for key in keys\n",
        "                ]\n",
        "                _data = torch.from_numpy(\n",
        "                    np.stack(data_arrays, axis=0)\n",
        "                )  # [batch, nt, nx, ny, nc]\n",
        "                _data = _data[\n",
        "                    ::reduced_batch,\n",
        "                    ::reduced_resolution_t,\n",
        "                    ::reduced_resolution,\n",
        "                    ::reduced_resolution,\n",
        "                    ...,\n",
        "                ]\n",
        "                _data = torch.permute(_data, (0, 2, 3, 1, 4))  # [batch, nx, ny, nt, nc]\n",
        "                gridx, gridy = (\n",
        "                    np.array(f[\"0023\"][\"grid\"][\"x\"], dtype=np.float32),\n",
        "                    np.array(f[\"0023\"][\"grid\"][\"y\"], dtype=np.float32),\n",
        "                )\n",
        "                mgridX, mgridY = np.meshgrid(gridx, gridy, indexing=\"ij\")\n",
        "                _grid = torch.stack(\n",
        "                    (torch.from_numpy(mgridX), torch.from_numpy(mgridY)), axis=-1\n",
        "                )\n",
        "                _grid = _grid[::reduced_resolution, ::reduced_resolution, ...]\n",
        "                _tsteps_t = torch.from_numpy(\n",
        "                    np.array(f[\"0023\"][\"grid\"][\"t\"], dtype=np.float32)\n",
        "                )\n",
        "\n",
        "                tsteps_t = _tsteps_t[::reduced_resolution_t]\n",
        "                self.data = _data\n",
        "                self.grid = _grid\n",
        "                self.tsteps_t = tsteps_t\n",
        "\n",
        "        if num_samples_max > 0:\n",
        "            num_samples_max = min(num_samples_max, self.data.shape[0])\n",
        "        else:\n",
        "            num_samples_max = self.data.shape[0]\n",
        "\n",
        "        test_idx = int(num_samples_max * test_ratio)\n",
        "        if if_test:\n",
        "            self.data = self.data[:test_idx]\n",
        "        else:\n",
        "            self.data = self.data[test_idx:num_samples_max]\n",
        "\n",
        "        # Time steps used as initial conditions\n",
        "        self.initial_step = initial_step\n",
        "\n",
        "        self.data = self.data if torch.is_tensor(self.data) else torch.tensor(self.data)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx, ..., : self.initial_step, :], self.data[idx], self.grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "l6D6e28tUR8o"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "logger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vusHAhyHUR5m"
      },
      "outputs": [],
      "source": [
        "filename = \"1D_Advection_Sols_beta0.1_reduced.hdf5\"\n",
        "base_path = \"/content/drive/MyDrive/\"\n",
        "\n",
        "# Training settings\n",
        "if_training = True\n",
        "continue_training = False\n",
        "num_workers = 0\n",
        "batch_size = 50\n",
        "initial_step = 10\n",
        "t_train = 200\n",
        "epochs = 500\n",
        "learning_rate = 1e-3\n",
        "scheduler_step = 100\n",
        "scheduler_gamma = 0.5\n",
        "model_update = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "11uwyEiqUR3N"
      },
      "outputs": [],
      "source": [
        "num_channels = 1\n",
        "size = 128  # Spatial grid size (important for CNO)\n",
        "\n",
        "# New CNO specific parameters (replacing FNO parameters)\n",
        "N_layers = 4\n",
        "N_res = 4\n",
        "N_res_neck = 4\n",
        "channel_multiplier = 16\n",
        "\n",
        "# Dataset preprocessing options\n",
        "single_file = True\n",
        "reduced_resolution = 1\n",
        "reduced_resolution_t = 1\n",
        "reduced_batch = 1\n",
        "\n",
        "# Plotting and bounds\n",
        "plot = False\n",
        "training_type = \"autoregressive\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "zUFbrkdbU8z0"
      },
      "outputs": [],
      "source": [
        "model_name = filename[:-5] + \"_CNO_75\"\n",
        "model_path = model_name + \".pt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "tGvH5F25qFHR",
        "outputId": "e84ecd89-ebd9-4e81-ddbb-1ed491242be9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1D_Advection_Sols_beta0.1_reduced_CNO_75.pt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "model_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "FzospQ51U8xd"
      },
      "outputs": [],
      "source": [
        "train_data = FNODatasetSingle(\n",
        "    filename,\n",
        "    reduced_resolution=reduced_resolution,\n",
        "    reduced_resolution_t=reduced_resolution_t,\n",
        "    reduced_batch=reduced_batch,\n",
        "    initial_step=initial_step,\n",
        "    saved_folder=base_path,\n",
        ")\n",
        "\n",
        "val_data = FNODatasetSingle(\n",
        "    filename,\n",
        "    reduced_resolution=reduced_resolution,\n",
        "    reduced_resolution_t=reduced_resolution_t,\n",
        "    reduced_batch=reduced_batch,\n",
        "    initial_step=initial_step,\n",
        "    if_test=True,\n",
        "    saved_folder=base_path,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3l_Jb32lU8uy"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, num_workers=num_workers, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81rx-0IL8RaY",
        "outputId": "103f3a31-4f75-4ef4-9f3b-dd75b37f821b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NUmber of batches 180\n",
            "Batch type: <class 'list'>\n",
            "Shapes of elements in batch:\n",
            "torch.Size([50, 256, 10, 1])\n",
            "torch.Size([50, 256, 41, 1])\n",
            "torch.Size([50, 256, 1])\n"
          ]
        }
      ],
      "source": [
        "print(\"NUmber of batches\",len(train_loader))\n",
        "for batch in train_loader:\n",
        "    print(f\"Batch type: {type(batch)}\")\n",
        "    if isinstance(batch, (tuple, list)):\n",
        "        print(\"Shapes of elements in batch:\")\n",
        "        for item in batch:\n",
        "            print(item.shape)\n",
        "    else:\n",
        "        print(batch.shape)\n",
        "    break  # only show the first batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "WyYdxqNdU8rl"
      },
      "outputs": [],
      "source": [
        "_, _data, _grid = next(iter(val_loader))\n",
        "t_train = min(t_train, _data.shape[-2])\n",
        "size = _data.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "fZxJuLtwVx6o"
      },
      "outputs": [],
      "source": [
        "model = CNO1d(\n",
        "    num_channels=num_channels,\n",
        "    width=channel_multiplier,  # Use channel_multiplier as width\n",
        "    initial_step=initial_step,\n",
        "    size=size,\n",
        "    N_layers=N_layers,\n",
        "    N_res=N_res,\n",
        "    N_res_neck=N_res_neck,\n",
        "    channel_multiplier=channel_multiplier,\n",
        "    use_bn=True\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "z73mAtuKVx3-"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=scheduler_step, gamma=scheduler_gamma)\n",
        "loss_fn = nn.MSELoss(reduction=\"mean\")\n",
        "loss_val_min = np.inf\n",
        "start_epoch = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "74j81YIlVx1N"
      },
      "outputs": [],
      "source": [
        "def metric_func(\n",
        "    pred, target, if_mean=True, Lx=1.0, Ly=1.0, Lz=1.0, iLow=4, iHigh=12, initial_step=1\n",
        "):\n",
        "    \"\"\"\n",
        "    code for calculate metrics discussed in the Brain-storming session\n",
        "    RMSE, normalized RMSE, max error, RMSE at the boundaries, conserved variables, RMSE in Fourier space, temporal sensitivity\n",
        "    \"\"\"\n",
        "    pred, target = pred.to(device), target.to(device)\n",
        "    # (batch, nx^i..., timesteps, nc)\n",
        "    # slice out `initial context` timesteps\n",
        "    pred = pred[..., initial_step:, :]\n",
        "    target = target[..., initial_step:, :]\n",
        "    idxs = target.size()\n",
        "    if len(idxs) == 4:  # 1D\n",
        "        pred = pred.permute(0, 3, 1, 2)\n",
        "        target = target.permute(0, 3, 1, 2)\n",
        "\n",
        "    idxs = target.size()\n",
        "    nb, nc, nt = idxs[0], idxs[1], idxs[-1]\n",
        "\n",
        "    # RMSE\n",
        "    err_mean = torch.sqrt(\n",
        "        torch.mean(\n",
        "            (pred.view([nb, nc, -1, nt]) - target.view([nb, nc, -1, nt])) ** 2, dim=2\n",
        "        )\n",
        "    )\n",
        "    err_RMSE = torch.mean(err_mean, axis=0)\n",
        "    nrm = torch.sqrt(torch.mean(target.view([nb, nc, -1, nt]) ** 2, dim=2))\n",
        "    err_nRMSE = torch.mean(err_mean / nrm, dim=0)\n",
        "\n",
        "    err_CSV = torch.sqrt(\n",
        "        torch.mean(\n",
        "            (\n",
        "                torch.sum(pred.view([nb, nc, -1, nt]), dim=2)\n",
        "                - torch.sum(target.view([nb, nc, -1, nt]), dim=2)\n",
        "            )\n",
        "            ** 2,\n",
        "            dim=0,\n",
        "        )\n",
        "    )\n",
        "    if len(idxs) == 4:\n",
        "        nx = idxs[2]\n",
        "        err_CSV /= nx\n",
        "\n",
        "    # worst case in all the data\n",
        "    err_Max = torch.max(\n",
        "        torch.max(\n",
        "            torch.abs(pred.view([nb, nc, -1, nt]) - target.view([nb, nc, -1, nt])),\n",
        "            dim=2,\n",
        "        )[0],\n",
        "        dim=0,\n",
        "    )[0]\n",
        "\n",
        "    if len(idxs) == 4:  # 1D\n",
        "        err_BD = (pred[:, :, 0, :] - target[:, :, 0, :]) ** 2\n",
        "        err_BD += (pred[:, :, -1, :] - target[:, :, -1, :]) ** 2\n",
        "        err_BD = torch.mean(torch.sqrt(err_BD / 2.0), dim=0)\n",
        "\n",
        "    if len(idxs) == 4:  # 1D\n",
        "        nx = idxs[2]\n",
        "        pred_F = torch.fft.rfft(pred, dim=2)\n",
        "        target_F = torch.fft.rfft(target, dim=2)\n",
        "        _err_F = (\n",
        "            torch.sqrt(torch.mean(torch.abs(pred_F - target_F) ** 2, axis=0)) / nx * Lx\n",
        "        )\n",
        "\n",
        "    err_F = torch.zeros([nc, 3, nt]).to(device)\n",
        "    err_F[:, 0] += torch.mean(_err_F[:, :iLow], dim=1)  # low freq\n",
        "    err_F[:, 1] += torch.mean(_err_F[:, iLow:iHigh], dim=1)  # middle freq\n",
        "    err_F[:, 2] += torch.mean(_err_F[:, iHigh:], dim=1)  # high freq\n",
        "\n",
        "    if if_mean:\n",
        "        return (\n",
        "            torch.mean(err_RMSE, dim=[0, -1]),\n",
        "            torch.mean(err_nRMSE, dim=[0, -1]),\n",
        "            torch.mean(err_CSV, dim=[0, -1]),\n",
        "            torch.mean(err_Max, dim=[0, -1]),\n",
        "            torch.mean(err_BD, dim=[0, -1]),\n",
        "            torch.mean(err_F, dim=[0, -1]),\n",
        "        )\n",
        "    return err_RMSE, err_nRMSE, err_CSV, err_Max, err_BD, err_F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "VE110_EWV-PA"
      },
      "outputs": [],
      "source": [
        "def metrics(\n",
        "    val_loader,\n",
        "    model,\n",
        "    Lx,\n",
        "    Ly,\n",
        "    Lz,\n",
        "    plot,\n",
        "    channel_plot,\n",
        "    model_name,\n",
        "    x_min,\n",
        "    x_max,\n",
        "    y_min,\n",
        "    y_max,\n",
        "    t_min,\n",
        "    t_max,\n",
        "    mode=\"CNO\",  # Changed default to CNO\n",
        "    initial_step=None,\n",
        "):\n",
        "    if mode == \"CNO\":  # Update to use CNO instead of FNO\n",
        "        with torch.no_grad():\n",
        "            itot = 0\n",
        "            for itot, (xx, yy, grid) in enumerate(val_loader):\n",
        "                xx = xx.to(device)  # noqa: PLW2901\n",
        "                yy = yy.to(device)  # noqa: PLW2901\n",
        "                grid = grid.to(device)  # noqa: PLW2901\n",
        "\n",
        "                pred = yy[..., :initial_step, :]\n",
        "                inp_shape = list(xx.shape)\n",
        "                inp_shape = inp_shape[:-2]\n",
        "                inp_shape.append(-1)\n",
        "\n",
        "                for _t in range(initial_step, yy.shape[-2]):\n",
        "                    inp = xx.reshape(inp_shape)\n",
        "                    im = model(inp, grid)\n",
        "                    pred = torch.cat((pred, im), -2)\n",
        "                    xx = torch.cat((xx[..., 1:, :], im), dim=-2)  # noqa: PLW2901\n",
        "\n",
        "                (\n",
        "                    _err_RMSE,\n",
        "                    _err_nRMSE,\n",
        "                    _err_CSV,\n",
        "                    _err_Max,\n",
        "                    _err_BD,\n",
        "                    _err_F,\n",
        "                ) = metric_func(\n",
        "                    pred,\n",
        "                    yy,\n",
        "                    if_mean=True,\n",
        "                    Lx=Lx,\n",
        "                    Ly=Ly,\n",
        "                    Lz=Lz,\n",
        "                    initial_step=initial_step,\n",
        "                )\n",
        "                if itot == 0:\n",
        "                    err_RMSE, err_nRMSE, err_CSV, err_Max, err_BD, err_F = (\n",
        "                        _err_RMSE,\n",
        "                        _err_nRMSE,\n",
        "                        _err_CSV,\n",
        "                        _err_Max,\n",
        "                        _err_BD,\n",
        "                        _err_F,\n",
        "                    )\n",
        "                    pred_plot = pred[:1]\n",
        "                    target_plot = yy[:1]\n",
        "                    val_l2_time = torch.zeros(yy.shape[-2]).to(device)\n",
        "                else:\n",
        "                    err_RMSE += _err_RMSE\n",
        "                    err_nRMSE += _err_nRMSE\n",
        "                    err_CSV += _err_CSV\n",
        "                    err_Max += _err_Max\n",
        "                    err_BD += _err_BD\n",
        "                    err_F += _err_F\n",
        "\n",
        "                    mean_dim = list(range(len(yy.shape) - 2))\n",
        "                    mean_dim.append(-1)\n",
        "                    mean_dim = tuple(mean_dim)\n",
        "                    val_l2_time += torch.sqrt(\n",
        "                        torch.mean((pred - yy) ** 2, dim=mean_dim)\n",
        "                    )\n",
        "\n",
        "    err_RMSE = np.array(err_RMSE.data.cpu() / itot)\n",
        "    err_nRMSE = np.array(err_nRMSE.data.cpu() / itot)\n",
        "    err_CSV = np.array(err_CSV.data.cpu() / itot)\n",
        "    err_Max = np.array(err_Max.data.cpu() / itot)\n",
        "    err_BD = np.array(err_BD.data.cpu() / itot)\n",
        "    err_F = np.array(err_F.data.cpu() / itot)\n",
        "    logger.info(f\"RMSE: {err_RMSE:.5f}\")\n",
        "    logger.info(f\"normalized RMSE: {err_nRMSE:.5f}\")\n",
        "    logger.info(f\"RMSE of conserved variables: {err_CSV:.5f}\")\n",
        "    logger.info(f\"Maximum value of rms error: {err_Max:.5f}\")\n",
        "    logger.info(f\"RMSE at boundaries: {err_BD:.5f}\")\n",
        "    logger.info(f\"RMSE in Fourier space: {err_F}\")\n",
        "\n",
        "    val_l2_time = val_l2_time / itot\n",
        "\n",
        "    return err_RMSE, err_nRMSE, err_CSV, err_Max, err_BD, err_F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "FtADO5gPZx9N"
      },
      "outputs": [],
      "source": [
        "checkpoint = torch.load(model_path, map_location=device)\n",
        "\n",
        "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "start_epoch = checkpoint[\"epoch\"]\n",
        "loss_val_min = checkpoint[\"loss\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDBtdmIIaGik",
        "outputId": "a40d4ef3-f1e1-4858-8941-94426f8479cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNO1d(\n",
              "  (model): CNO1d_DLGN(\n",
              "    (lift): LiftProjectBlock_DLGN(\n",
              "      (inter_CNOBlock): CNOBlock_DLGN(\n",
              "        (convolution): Conv1d(11, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        (batch_norm): Identity()\n",
              "        (gating): DLGN_Gate(\n",
              "          (transformer): GatingTransformer(\n",
              "            (channel_transform): Conv1d(11, 64, kernel_size=(1,), stride=(1,))\n",
              "          )\n",
              "          (gate_weights): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        )\n",
              "        (dlgn_layer): DLGN_Layer()\n",
              "      )\n",
              "      (convolution): Conv1d(64, 8, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "    )\n",
              "    (project): LiftProjectBlock_DLGN(\n",
              "      (inter_CNOBlock): CNOBlock_DLGN(\n",
              "        (convolution): Conv1d(16, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        (batch_norm): Identity()\n",
              "        (gating): DLGN_Gate(\n",
              "          (transformer): GatingTransformer(\n",
              "            (channel_transform): Conv1d(11, 64, kernel_size=(1,), stride=(1,))\n",
              "          )\n",
              "          (gate_weights): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        )\n",
              "        (dlgn_layer): DLGN_Layer()\n",
              "      )\n",
              "      (convolution): Conv1d(64, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "    )\n",
              "    (encoder): ModuleList(\n",
              "      (0): CNOBlock_DLGN(\n",
              "        (convolution): Conv1d(8, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        (batch_norm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (gating): DLGN_Gate(\n",
              "          (transformer): GatingTransformer(\n",
              "            (channel_transform): Conv1d(11, 16, kernel_size=(1,), stride=(1,))\n",
              "          )\n",
              "          (gate_weights): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        )\n",
              "        (dlgn_layer): DLGN_Layer()\n",
              "      )\n",
              "      (1): CNOBlock_DLGN(\n",
              "        (convolution): Conv1d(16, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        (batch_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (gating): DLGN_Gate(\n",
              "          (transformer): GatingTransformer(\n",
              "            (channel_transform): Conv1d(11, 32, kernel_size=(1,), stride=(1,))\n",
              "          )\n",
              "          (gate_weights): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        )\n",
              "        (dlgn_layer): DLGN_Layer()\n",
              "      )\n",
              "      (2): CNOBlock_DLGN(\n",
              "        (convolution): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        (batch_norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (gating): DLGN_Gate(\n",
              "          (transformer): GatingTransformer(\n",
              "            (channel_transform): Conv1d(11, 64, kernel_size=(1,), stride=(1,))\n",
              "          )\n",
              "          (gate_weights): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        )\n",
              "        (dlgn_layer): DLGN_Layer()\n",
              "      )\n",
              "      (3): CNOBlock_DLGN(\n",
              "        (convolution): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        (batch_norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (gating): DLGN_Gate(\n",
              "          (transformer): GatingTransformer(\n",
              "            (channel_transform): Conv1d(11, 128, kernel_size=(1,), stride=(1,))\n",
              "          )\n",
              "          (gate_weights): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        )\n",
              "        (dlgn_layer): DLGN_Layer()\n",
              "      )\n",
              "    )\n",
              "    (ED_expansion): ModuleList(\n",
              "      (0): CNOBlock_DLGN(\n",
              "        (convolution): Conv1d(8, 8, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        (batch_norm): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (gating): DLGN_Gate(\n",
              "          (transformer): GatingTransformer(\n",
              "            (channel_transform): Conv1d(11, 8, kernel_size=(1,), stride=(1,))\n",
              "          )\n",
              "          (gate_weights): Conv1d(8, 8, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        )\n",
              "        (dlgn_layer): DLGN_Layer()\n",
              "      )\n",
              "      (1): CNOBlock_DLGN(\n",
              "        (convolution): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        (batch_norm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (gating): DLGN_Gate(\n",
              "          (transformer): GatingTransformer(\n",
              "            (channel_transform): Conv1d(11, 16, kernel_size=(1,), stride=(1,))\n",
              "          )\n",
              "          (gate_weights): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        )\n",
              "        (dlgn_layer): DLGN_Layer()\n",
              "      )\n",
              "      (2): CNOBlock_DLGN(\n",
              "        (convolution): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        (batch_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (gating): DLGN_Gate(\n",
              "          (transformer): GatingTransformer(\n",
              "            (channel_transform): Conv1d(11, 32, kernel_size=(1,), stride=(1,))\n",
              "          )\n",
              "          (gate_weights): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        )\n",
              "        (dlgn_layer): DLGN_Layer()\n",
              "      )\n",
              "      (3): CNOBlock_DLGN(\n",
              "        (convolution): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        (batch_norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (gating): DLGN_Gate(\n",
              "          (transformer): GatingTransformer(\n",
              "            (channel_transform): Conv1d(11, 64, kernel_size=(1,), stride=(1,))\n",
              "          )\n",
              "          (gate_weights): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        )\n",
              "        (dlgn_layer): DLGN_Layer()\n",
              "      )\n",
              "      (4): CNOBlock_DLGN(\n",
              "        (convolution): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        (batch_norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (gating): DLGN_Gate(\n",
              "          (transformer): GatingTransformer(\n",
              "            (channel_transform): Conv1d(11, 128, kernel_size=(1,), stride=(1,))\n",
              "          )\n",
              "          (gate_weights): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        )\n",
              "        (dlgn_layer): DLGN_Layer()\n",
              "      )\n",
              "    )\n",
              "    (decoder): ModuleList(\n",
              "      (0): CNOBlock_DLGN(\n",
              "        (convolution): Conv1d(128, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        (batch_norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (gating): DLGN_Gate(\n",
              "          (transformer): GatingTransformer(\n",
              "            (channel_transform): Conv1d(11, 64, kernel_size=(1,), stride=(1,))\n",
              "          )\n",
              "          (gate_weights): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        )\n",
              "        (dlgn_layer): DLGN_Layer()\n",
              "      )\n",
              "      (1): CNOBlock_DLGN(\n",
              "        (convolution): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        (batch_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (gating): DLGN_Gate(\n",
              "          (transformer): GatingTransformer(\n",
              "            (channel_transform): Conv1d(11, 32, kernel_size=(1,), stride=(1,))\n",
              "          )\n",
              "          (gate_weights): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        )\n",
              "        (dlgn_layer): DLGN_Layer()\n",
              "      )\n",
              "      (2): CNOBlock_DLGN(\n",
              "        (convolution): Conv1d(64, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        (batch_norm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (gating): DLGN_Gate(\n",
              "          (transformer): GatingTransformer(\n",
              "            (channel_transform): Conv1d(11, 16, kernel_size=(1,), stride=(1,))\n",
              "          )\n",
              "          (gate_weights): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        )\n",
              "        (dlgn_layer): DLGN_Layer()\n",
              "      )\n",
              "      (3): CNOBlock_DLGN(\n",
              "        (convolution): Conv1d(32, 8, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        (batch_norm): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (gating): DLGN_Gate(\n",
              "          (transformer): GatingTransformer(\n",
              "            (channel_transform): Conv1d(11, 8, kernel_size=(1,), stride=(1,))\n",
              "          )\n",
              "          (gate_weights): Conv1d(8, 8, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        )\n",
              "        (dlgn_layer): DLGN_Layer()\n",
              "      )\n",
              "    )\n",
              "    (res_nets): ModuleList(\n",
              "      (0): ResNet_DLGN(\n",
              "        (res_blocks): ModuleList(\n",
              "          (0-3): 4 x ResidualBlock_DLGN(\n",
              "            (convolution1): Conv1d(8, 8, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "            (convolution2): Conv1d(8, 8, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "            (batch_norm1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (batch_norm2): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (gating1): DLGN_Gate(\n",
              "              (transformer): GatingTransformer(\n",
              "                (channel_transform): Conv1d(11, 8, kernel_size=(1,), stride=(1,))\n",
              "              )\n",
              "              (gate_weights): Conv1d(8, 8, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "            )\n",
              "            (gating2): DLGN_Gate(\n",
              "              (transformer): GatingTransformer(\n",
              "                (channel_transform): Conv1d(11, 8, kernel_size=(1,), stride=(1,))\n",
              "              )\n",
              "              (gate_weights): Conv1d(8, 8, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "            )\n",
              "            (dlgn_layer1): DLGN_Layer()\n",
              "            (dlgn_layer2): DLGN_Layer()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1): ResNet_DLGN(\n",
              "        (res_blocks): ModuleList(\n",
              "          (0-3): 4 x ResidualBlock_DLGN(\n",
              "            (convolution1): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "            (convolution2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "            (batch_norm1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (batch_norm2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (gating1): DLGN_Gate(\n",
              "              (transformer): GatingTransformer(\n",
              "                (channel_transform): Conv1d(11, 16, kernel_size=(1,), stride=(1,))\n",
              "              )\n",
              "              (gate_weights): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "            )\n",
              "            (gating2): DLGN_Gate(\n",
              "              (transformer): GatingTransformer(\n",
              "                (channel_transform): Conv1d(11, 16, kernel_size=(1,), stride=(1,))\n",
              "              )\n",
              "              (gate_weights): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "            )\n",
              "            (dlgn_layer1): DLGN_Layer()\n",
              "            (dlgn_layer2): DLGN_Layer()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (2): ResNet_DLGN(\n",
              "        (res_blocks): ModuleList(\n",
              "          (0-3): 4 x ResidualBlock_DLGN(\n",
              "            (convolution1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "            (convolution2): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "            (batch_norm1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (batch_norm2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (gating1): DLGN_Gate(\n",
              "              (transformer): GatingTransformer(\n",
              "                (channel_transform): Conv1d(11, 32, kernel_size=(1,), stride=(1,))\n",
              "              )\n",
              "              (gate_weights): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "            )\n",
              "            (gating2): DLGN_Gate(\n",
              "              (transformer): GatingTransformer(\n",
              "                (channel_transform): Conv1d(11, 32, kernel_size=(1,), stride=(1,))\n",
              "              )\n",
              "              (gate_weights): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "            )\n",
              "            (dlgn_layer1): DLGN_Layer()\n",
              "            (dlgn_layer2): DLGN_Layer()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (3): ResNet_DLGN(\n",
              "        (res_blocks): ModuleList(\n",
              "          (0-3): 4 x ResidualBlock_DLGN(\n",
              "            (convolution1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "            (convolution2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "            (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (batch_norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (gating1): DLGN_Gate(\n",
              "              (transformer): GatingTransformer(\n",
              "                (channel_transform): Conv1d(11, 64, kernel_size=(1,), stride=(1,))\n",
              "              )\n",
              "              (gate_weights): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "            )\n",
              "            (gating2): DLGN_Gate(\n",
              "              (transformer): GatingTransformer(\n",
              "                (channel_transform): Conv1d(11, 64, kernel_size=(1,), stride=(1,))\n",
              "              )\n",
              "              (gate_weights): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "            )\n",
              "            (dlgn_layer1): DLGN_Layer()\n",
              "            (dlgn_layer2): DLGN_Layer()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (res_net_neck): ResNet_DLGN(\n",
              "      (res_blocks): ModuleList(\n",
              "        (0-3): 4 x ResidualBlock_DLGN(\n",
              "          (convolution1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "          (convolution2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "          (batch_norm1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (batch_norm2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (gating1): DLGN_Gate(\n",
              "            (transformer): GatingTransformer(\n",
              "              (channel_transform): Conv1d(11, 128, kernel_size=(1,), stride=(1,))\n",
              "            )\n",
              "            (gate_weights): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "          )\n",
              "          (gating2): DLGN_Gate(\n",
              "            (transformer): GatingTransformer(\n",
              "              (channel_transform): Conv1d(11, 128, kernel_size=(1,), stride=(1,))\n",
              "            )\n",
              "            (gate_weights): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "          )\n",
              "          (dlgn_layer1): DLGN_Layer()\n",
              "          (dlgn_layer2): DLGN_Layer()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "model.to(device)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "V23ojKfGaK-s"
      },
      "outputs": [],
      "source": [
        "all_preds_val = []\n",
        "all_truth_val = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MI-9TUh_aK8W",
        "outputId": "0c46d65a-d3e4-47a9-b838-3774f6b0abbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:18<00:00,  1.07it/s]\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    for xx, yy, grid in tqdm(val_loader):  # or use test_loader if available\n",
        "        xx, yy, grid = xx.to(device), yy.to(device), grid.to(device)\n",
        "        pred = yy[..., :initial_step, :]\n",
        "        inp_shape = list(xx.shape[:-2]) + [-1]\n",
        "\n",
        "        for t in range(initial_step, yy.shape[-2]):\n",
        "            inp = xx.reshape(inp_shape)\n",
        "            im = model(inp, grid)\n",
        "            pred = torch.cat((pred, im), -2)\n",
        "            xx = torch.cat((xx[..., 1:, :], im), dim=-2)\n",
        "\n",
        "        all_preds_val.append(pred.cpu().numpy())\n",
        "        all_truth_val.append(yy[..., :pred.shape[-2], :].cpu().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QtRHc_4a23U",
        "outputId": "d5ab64d5-f630-41ba-a097-720f77662cb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample keys / structure:\n",
            "<class 'tuple'>\n",
            "Element 0: shape torch.Size([256, 10, 1])\n",
            "Element 1: shape torch.Size([256, 41, 1])\n",
            "Element 2: shape torch.Size([256, 1])\n"
          ]
        }
      ],
      "source": [
        "sample = val_loader.dataset[0]\n",
        "print(\"Sample keys / structure:\")\n",
        "if isinstance(sample, dict):\n",
        "    print(sample.keys())\n",
        "else:\n",
        "    print(type(sample))\n",
        "    if isinstance(sample, tuple):\n",
        "        for i, s in enumerate(sample):\n",
        "            print(f\"Element {i}: shape {getattr(s, 'shape', type(s))}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "QKDXvApqbalW"
      },
      "outputs": [],
      "source": [
        "predictions = np.concatenate(all_preds_val, axis=0)  # shape: (n_samples, n_t, n_x)\n",
        "ground_truth = np.concatenate(all_truth_val, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "-Gk0KQ6cbfAc"
      },
      "outputs": [],
      "source": [
        "xx, yy, grid = next(iter(val_loader))\n",
        "x = np.sort(np.unique(grid[:, 0].cpu().numpy()))  # shape: (n_x,)\n",
        "t = np.linspace(0, 1, yy.shape[-2])               # shape: (n_t,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4srNNjtaK29",
        "outputId": "220e7e6f-00a1-414a-c321-5b1a50140308"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved predictions and grids for SINDy: 'predictions_for_sindy.npz'\n"
          ]
        }
      ],
      "source": [
        "np.savez(\"predictions_for_sindy.npz\", u_pred=predictions, u_true=ground_truth, x=x, t=t)\n",
        "print(\"✅ Saved predictions and grids for SINDy: 'predictions_for_sindy.npz'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDTaLnicbr61",
        "outputId": "de6affc4-48fd-4e05-cf47-b0dd16209c59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pysindy in /usr/local/lib/python3.11/dist-packages (1.7.5)\n",
            "Requirement already satisfied: numpy==1.24.0 in /usr/local/lib/python3.11/dist-packages (1.24.0)\n",
            "Requirement already satisfied: scikit-learn>=0.23 in /usr/local/lib/python3.11/dist-packages (from pysindy) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pysindy) (1.15.3)\n",
            "Requirement already satisfied: derivative in /usr/local/lib/python3.11/dist-packages (from pysindy) (0.6.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from pysindy) (3.10.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from pysindy) (3.31.6)\n",
            "Requirement already satisfied: scs!=2.1.4,>=2.1 in /usr/local/lib/python3.11/dist-packages (from pysindy) (3.2.7.post2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.23->pysindy) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.23->pysindy) (3.6.0)\n",
            "Requirement already satisfied: importlib-metadata>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from derivative->pysindy) (8.7.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pysindy) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pysindy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pysindy) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pysindy) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pysindy) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pysindy) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pysindy) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pysindy) (2.9.0.post0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=7.1.0->derivative->pysindy) (3.21.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->pysindy) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "pip install pysindy numpy==1.24.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lC40-rFydxTf",
        "outputId": "fa053312-d4a5-49de-e1b7-ca2e194afd85"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 256, 41, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "u_pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YYk9_f6dexD",
        "outputId": "7cba2521-2b67-4718-9a1c-465df1eb9610"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(256,)\n"
          ]
        }
      ],
      "source": [
        "xL = 1.0  # Left boundary\n",
        "xR = 0.0  # Right boundary\n",
        "nx = u_pred.shape[1]  # Extract the number of spatial points (from prediction shape)\n",
        "\n",
        "dx = (xR - xL) / nx\n",
        "xe = np.linspace(xL, xR, nx + 1)  # Edge points\n",
        "x = xe[:-1] + 0.5 * dx  # Cell centers (excluding the last edge)\n",
        "\n",
        "# Now x should be a 1D array with shape (nx,)\n",
        "print(x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dd-PeZu1dgUh",
        "outputId": "35acca1e-5537-4faa-b336-f33c37cbe93e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(41,)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "t.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "HRsCw6mQb4yV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pysindy as ps\n",
        "\n",
        "# ---- Load saved predictions ----\n",
        "data = np.load(\"predictions_for_sindy.npz\")\n",
        "u_pred = data[\"u_true\"]                # (n_x,)\n",
        "t = data[\"t\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfPGvCR2cKqv",
        "outputId": "86ab7419-8a84-471e-f531-26d9c2c6cb3e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 256, 41, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "u_pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAtisc7PcSGK",
        "outputId": "d5bf410f-0b04-41b3-c5d3-9239a82a7a31"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(41,)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "t.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFUxqMewcGoY",
        "outputId": "8bf25ad8-ff80-4a2c-9056-48a2581ad0d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(256,)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "wkCFBYSmb4v7"
      },
      "outputs": [],
      "source": [
        "u = u_pred[0]                 # shape: (n_t, n_x)\n",
        "\n",
        "# ---- Set up grid spacing\n",
        "dt = t[1] - t[0]\n",
        "dx = x[1] - x[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "E0jG4Amxb4uD"
      },
      "outputs": [],
      "source": [
        "fd = ps.FiniteDifference()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "9oc6-lgjb4sG"
      },
      "outputs": [],
      "source": [
        "library = ps.PDELibrary(\n",
        "    library_functions=[lambda u: u],\n",
        "    function_names=[lambda s: s],\n",
        "    derivative_order=3,\n",
        "    spatial_grid=x,\n",
        "    include_interaction=False,\n",
        "    is_uniform=True,\n",
        "    include_bias=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "eMv9VQHzebJq"
      },
      "outputs": [],
      "source": [
        "model = ps.SINDy(\n",
        "    optimizer=ps.STLSQ(alpha=1e-5, threshold=1e-3),\n",
        "    feature_library=library,\n",
        "    differentiation_method=fd\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMqxcjrdebHV",
        "outputId": "418a88a8-89d3-4a85-b71e-8a81dcb4a145"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(x0)' = -0.156 x0_1\n"
          ]
        }
      ],
      "source": [
        "model.fit(u, t=dt)\n",
        "model.print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0sdhfkhebFU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AdP2_P6oebDE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBswq5ej9zTD"
      },
      "source": [
        "Test run with batch size 50\n",
        "epoch: 0, loss: 0.63057, t2-t1: 463.56203, trainL2: 9.55097, testL2: 0.38045\n",
        "epoch: 1, loss: 0.55014, t2-t1: 460.28001, trainL2: 4.16928, testL2: 0.31352\n",
        "epoch: 2, loss: 0.13798, t2-t1: 459.41851, trainL2: 2.85387, testL2: 0.06545\n",
        "epoch: 3, loss: 0.09339, t2-t1: 460.18633, trainL2: 1.86878, testL2: 0.07487\n",
        "epoch: 4, loss: 0.04525, t2-t1: 462.79572, trainL2: 1.96279, testL2: 0.02735\n",
        "epoch: 5, loss: 0.03533, t2-t1: 460.98556, trainL2: 1.58974, testL2: 0.02083\n",
        "epoch: 6, loss: 0.06565, t2-t1: 460.80017, trainL2: 1.52914, testL2: 0.05132\n",
        "epoch: 7, loss: 0.04068, t2-t1: 458.44843, trainL2: 1.72168, testL2: 0.02438\n",
        "epoch: 8, loss: 0.04329, t2-t1: 459.96253, trainL2: 1.50155, testL2: 0.02675\n",
        "epoch: 9, loss: 0.05211, t2-t1: 455.91932, trainL2: 1.49865, testL2: 0.03940"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXHp6_WCV-Jo"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}